{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2ZYtrASijE_"
      },
      "source": [
        "# Week 5: Document Similarity\n",
        "\n",
        "In some applications, it may be difficult to define the classes that we want to use in classification ahead of time.  Or, classes might be made up various subclasses (which differ in terms of the vocabulary used).  In both of these cases (and others), it might be more appropriate to think about **document similarity**.  For a new document, can we find the most similar document in our collection?\n",
        "\n",
        "### Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjmEqk0WinXj"
      },
      "outputs": [],
      "source": [
        "###uncomment if working on colab\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06fwJf9ci2tq"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDpwcq7UijFF"
      },
      "source": [
        "Now lets get a document collection.  We are going to use the Gutenberg collection of books.  We will get the tokenised content of each book and store it in a dictionary (key = the fileid of the book) for easy access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1DgvRiKU8nV"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import gutenberg\n",
        "book_ids=gutenberg.fileids()\n",
        "books={b:gutenberg.words(b) for b in book_ids}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ol3UqQxHU8nW"
      },
      "outputs": [],
      "source": [
        "books[book_ids[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6trbihIijFK"
      },
      "source": [
        "We now need to normalise the tokens in the documents and construct a *bag-of-words* document representation.  Combining some of the functionality we have been working over the past few weeks (which we have imported from utils.py), we could use something like this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7cR-gxUijFP"
      },
      "outputs": [],
      "source": [
        "book_reps={key:FreqDist(normalise(book)) for key,book in books.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75oZH7ozk4Wv"
      },
      "source": [
        "Let's have a look at the representation of first book:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTfwqLWPijFR"
      },
      "outputs": [],
      "source": [
        "print(book_reps[book_ids[0]].items())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sokt9hE9ijFU"
      },
      "source": [
        "## Measuring Similarity\n",
        "We are going to use the cosine measure to determine how similar two books are.  This can be defined in terms of the dot products of vectors:\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "\\mbox{sim}_{\\mbox{cosine}}(A,B) = \\frac{A.B}{\\sqrt{A.A \\times B.B}}\n",
        "\\end{eqnarray*}\n",
        "\n",
        "where the dot product of two vectors, A and B, is defined as:\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "A.B = \\sum_{\\mbox{f}} \\mbox{weight}(A,f)\\times \\mbox{weight}(B,f) \n",
        "\\end{eqnarray*}\n",
        "\n",
        "and $\\mbox{weight}(X,f)$ tells us the value associated with feature $f$ in the vector representation of $X$\n",
        "\n",
        "### Exercise 1.1\n",
        "* Write a function `dot` which takes two documents (represented as dictionaries or `FreqDist`s) and returns their dot product\n",
        "* Test it out on the first two books in Gutenberg.  You should get the answer 3882298!\n",
        "* Why is the number so large?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tCel2Q8ijFV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER7pPHzOijFY"
      },
      "source": [
        "### Exercise 1.2\n",
        "* Write a function `cos_sim` which takes two documents (represented as dictionaries or `FreqDist`s) and returns their cosine similarity.\n",
        "* Your function should make 3 calls to the `dot` function you have already defined\n",
        "* If you test it out on the first two documents in the finance collection you should get 0.72 (to 2S.F.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_pDnxOfijFZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_2viT-oijFf"
      },
      "source": [
        "### Exercise 1.3\n",
        "* Write some code that will compute the similarity of every document in a collection with every document in another collection\n",
        "* Write code to compute the average similarity of two collections\n",
        "* Compute (and display) the average similarity of the book collection to itself\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REy6s_38ijFf"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lesV57JAU8nf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpnSYEMlijFi"
      },
      "source": [
        "## Beyond Frequency\n",
        "Frequency of a word in a document does not make a very good weight because some words occur very frequently in all documents.  If two rare words occur in both of our pair of documents, that should add more to their perceived similarity than if two common words occur in both of our pair of documents.\n",
        "\n",
        "### TF-IDF\n",
        "A commonly used weight is tf-idf which stands for **term frequency, inverse document frequency**\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "\\mbox{tf-idf}(D_i,f) = tf(D_i,f) \\times idf(D_i,f)\n",
        "\\end{eqnarray*}\n",
        "\n",
        "where $tf(D_i,f)$ is simply the frequency of feature f in document $D_i$\n",
        "and\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "idf(D_i,f) = log \\frac{N}{df(f)}\n",
        "\\end{eqnarray*}\n",
        "\n",
        "where $N$ is the total number of documents and $\\mbox{df}(f)$ is the number of documents containing $f$:  \n",
        "\n",
        "\\begin{eqnarray*}\n",
        "df(f)=|\\{i|\\mbox{freq}(D_i,f)>0\\}|\n",
        "\\end{eqnarray*}\n",
        "\n",
        "The code below will take a list of documents (represented as dictionaries) and compute the document frequency for each feature.  Test it out on one the collection of books."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dWqctt_ijFj"
      },
      "outputs": [],
      "source": [
        "def doc_freq(doclist):\n",
        "    df={}\n",
        "    for doc in doclist:\n",
        "        for feat in doc.keys():\n",
        "            df[feat]=df.get(feat,0)+1\n",
        "            \n",
        "    return df\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lL19Sg8lTEf"
      },
      "outputs": [],
      "source": [
        "doc_freq(book_reps.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b78F6_p2ijFm"
      },
      "source": [
        "### Exercise 2.1\n",
        "* Write a function which will compute the idf values for features given a list of documents\n",
        "* Use it to compute idf values for features given the entire list of books in the book collection\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWo0NQ5SijFm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiFxAmK1ijFp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOL89cF-ijFs"
      },
      "source": [
        "### Exercise 2.2\n",
        "* Write a function `convert_to_tfidf` that takes two arguments:\n",
        "    * a dictionary of documents mapping fileids to documents\n",
        "        * where each document is represented as a dictionary or FreqDist {feat:freq})\n",
        "    * a dictionary containing idf values\n",
        "* and outputs a dictionary of documents where each document is represented as a dictionary or FreqDist with tfidf weights {feat:tfidf}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khxO_GxLijFv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfQIkEK4ijFy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbxJQxEQijF1"
      },
      "source": [
        "### Exercise 2.3\n",
        "* Recompute the average similarity between the collection of books (as in Ex 1.3).\n",
        "* What do you notice?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yyc36RIeijF1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffcgIYBhijF4"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI0J_G2rU8nl"
      },
      "source": [
        "### Exercise 2.4\n",
        "For each book in the collection, find it's most similar book (NOT INCLUDING ITSELF!).\n",
        "Output your results in a table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkiwGRAuU8nm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJeYsGqgU8nm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huEGHZ3sU8nm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}