{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meI5qrz3x0WS"
      },
      "source": [
        "# Week 6 Lab: Lexical Semantics\n",
        "\n",
        "This week we turn our attention to lexical semantics, i.e., the meaning of words.  In this lab, you will be\n",
        "* exploring the WordNet resource\n",
        "* learning about lexical relations such as synonymy and hyponymy\n",
        "* quantifying semantic similarity via distance in the WordNet hierarchy\n",
        "* comparing WordNet similarity scores with human synonymy judgements\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9-TaPbgx0WU"
      },
      "outputs": [],
      "source": [
        "###uncomment if working on colab\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT_oEZgEx0Wa"
      },
      "source": [
        "First, lets import WordNet from the nltk library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr0Q3HlPx0Wa"
      },
      "outputs": [],
      "source": [
        "#import nltk\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('wordnet_ic')\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import wordnet_ic as wn_ic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eRGZcKhx0Wh"
      },
      "source": [
        "## Navigating WordNet\n",
        "\n",
        "Central to the organisation of WordNet is the idea of a synset.  Words have senses and senses are grouped with synonymous senses (of other words) in **synsets**\n",
        "\n",
        "If you want to find out which synsets a word belongs to, you use the `synsets` function.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB2PqZqbx0Wi",
        "outputId": "e59ce27b-679a-4818-fdb2-345c2141e4e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Synset('plant.n.01'),\n",
              " Synset('plant.n.02'),\n",
              " Synset('plant.n.03'),\n",
              " Synset('plant.n.04'),\n",
              " Synset('plant.v.01'),\n",
              " Synset('implant.v.01'),\n",
              " Synset('establish.v.02'),\n",
              " Synset('plant.v.04'),\n",
              " Synset('plant.v.05'),\n",
              " Synset('plant.v.06')]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "wn.synsets(\"plant\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfTgERxcx0Wn"
      },
      "source": [
        "The output is a list of `Synset` objects each of which has a unique identifier containing one of its words, its part of speech and a number.  `Synset('book.n.01')` is the first noun sense of *book*.  However the word book is also in `Synset('record.n.05')` which is the fifth noun sense of *record*.  Lets inspect this synset further."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhydtCxOx0Wo",
        "outputId": "ef25885a-594a-457b-a164-5612276da4e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['record', 'record_book', 'book']\n",
            "a compilation of the known facts regarding something or someone\n",
            "[\"Al Smith used to say, `Let's look at the record'\", 'his name is in all the record books']\n"
          ]
        }
      ],
      "source": [
        "book_synsets=wn.synsets('book')\n",
        "recordn5=book_synsets[2]\n",
        "print(recordn5.lemma_names())  #get the words in the synset\n",
        "print(recordn5.definition())   #get the definition of the synset\n",
        "print(recordn5.examples())  #get examples of the words used in this sense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtlLVc0LEHMo",
        "outputId": "dc3f504f-a76b-4afb-c398-a500dca7c182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1:buildings for carrying on industrial labor\n",
            "2:(botany) a living organism lacking the power of locomotion\n",
            "3:an actor situated in the audience whose acting is rehearsed but seems spontaneous to the audience\n",
            "4:something planted secretly for discovery by another\n",
            "5:put or set (seeds, seedlings, or plants) into the ground\n",
            "6:fix or set securely or deeply\n",
            "7:set up or lay the groundwork for\n",
            "8:place into a river\n",
            "9:place something or someone in a certain position in order to secretly observe or deceive\n",
            "10:put firmly in the mind\n"
          ]
        }
      ],
      "source": [
        "plant_synsets=wn.synsets('plant')\n",
        "for i,s in enumerate(plant_synsets):\n",
        "    print(\"{}:{}\".format(i+1,s.definition()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7TXDt_tx0Ws"
      },
      "source": [
        "If you only want to find synsets associated with a particular part of speech of a word then you can give `synsets` an extra argument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BoxPB5kx0Wt",
        "outputId": "3cfc4917-9bcb-4a36-ffa1-08e4c654f23e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Synset('red.n.01'), Synset('red.n.02'), Synset('bolshevik.n.01'), Synset('loss.n.06')]\n"
          ]
        }
      ],
      "source": [
        "#all of the WN POS tags\n",
        "parts_of_speech=[wn.NOUN,wn.VERB,wn.ADJ,wn.ADV]\n",
        "\n",
        "print(wn.synsets(\"red\",parts_of_speech[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuCYGSbIx0Ww"
      },
      "source": [
        "### Exercise 1.1\n",
        "* Write code to compute the number of synsets of each part of speech (noun, verb, adjective and adverb) for each of the following words:- book, chicken, counter, twig, fast, plant\n",
        "* Store and display the information using a Pandas dataframe\n",
        "\n",
        "Hint: you could use a nested list comprehension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Gqn533ZUx0Wx",
        "outputId": "c1291180-5d4b-4df5-c053-4ecb367c886f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n</th>\n",
              "      <th>v</th>\n",
              "      <th>a</th>\n",
              "      <th>r</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>book</th>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chicken</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counter</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>twig</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fast</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>plant</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          n  v   a  r\n",
              "book     11  4   0  0\n",
              "chicken   4  0   1  0\n",
              "counter   9  2   1  1\n",
              "twig      1  2   0  0\n",
              "fast      1  2  10  2\n",
              "plant     4  6   0  0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "words=[\"book\",\"chicken\",\"counter\",\"twig\",\"fast\",\"plant\"]\n",
        "\n",
        "results=[[len(wn.synsets(word,pos)) for pos in parts_of_speech]for word in words]\n",
        "\n",
        "df =pd.DataFrame(results,index=words,columns=parts_of_speech)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5W1JRbJGNEM"
      },
      "source": [
        "The `Synset` object has a `lemmas()` method which returns all of the lemmas / word senses which make up that synset.  Remember, it is one sense of each word which is considered as synonymous within the synset.  Not every sense of *plant* is considered synonymous with every sense of *works*.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTyC3bLjEHMq",
        "outputId": "4e7c5732-856f-4b40-ccb1-5e2df2d30c1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:[Lemma('plant.n.01.plant'), Lemma('plant.n.01.works'), Lemma('plant.n.01.industrial_plant')]\n",
            "1:[Lemma('plant.n.02.plant'), Lemma('plant.n.02.flora'), Lemma('plant.n.02.plant_life')]\n",
            "2:[Lemma('plant.n.03.plant')]\n",
            "3:[Lemma('plant.n.04.plant')]\n",
            "4:[Lemma('plant.v.01.plant'), Lemma('plant.v.01.set')]\n",
            "5:[Lemma('implant.v.01.implant'), Lemma('implant.v.01.engraft'), Lemma('implant.v.01.embed'), Lemma('implant.v.01.imbed'), Lemma('implant.v.01.plant')]\n",
            "6:[Lemma('establish.v.02.establish'), Lemma('establish.v.02.found'), Lemma('establish.v.02.plant'), Lemma('establish.v.02.constitute'), Lemma('establish.v.02.institute')]\n",
            "7:[Lemma('plant.v.04.plant')]\n",
            "8:[Lemma('plant.v.05.plant')]\n",
            "9:[Lemma('plant.v.06.plant'), Lemma('plant.v.06.implant')]\n"
          ]
        }
      ],
      "source": [
        "for i,s in enumerate(plant_synsets):\n",
        "    print(\"{}:{}\".format(i,s.lemmas()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptpP_UBxEHMq"
      },
      "source": [
        "Access the word form of a `Lemma` using its `names()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSO48Bk0EHMq",
        "outputId": "eac5ab65-be25-43bd-e1ab-4db8b953fad0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:['cat', 'true_cat']\n",
            "\tfeline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats\n",
            "1:['guy', 'cat', 'hombre', 'bozo']\n",
            "\tan informal term for a youth or man\n",
            "2:['cat']\n",
            "\ta spiteful woman gossip\n",
            "3:['kat', 'khat', 'qat', 'quat', 'cat', 'Arabian_tea', 'African_tea']\n",
            "\tthe leaves of the shrub Catha edulis which are chewed like tobacco or used to make tea; has the effect of a euphoric stimulant\n",
            "4:[\"cat-o'-nine-tails\", 'cat']\n",
            "\ta whip with nine knotted cords\n",
            "5:['Caterpillar', 'cat']\n",
            "\ta large tracked vehicle that is propelled by two endless metal belts; frequently used for moving earth in construction and farm work\n",
            "6:['big_cat', 'cat']\n",
            "\tany of several large cats typically able to roar and living in the wild\n",
            "7:['computerized_tomography', 'computed_tomography', 'CT', 'computerized_axial_tomography', 'computed_axial_tomography', 'CAT']\n",
            "\ta method of examining body organs by scanning them with X rays and using a computer to construct a series of cross-sectional scans along a single axis\n"
          ]
        }
      ],
      "source": [
        "cat_synsets = wn.synsets(\"cat\",wn.NOUN)\n",
        "for i,s in enumerate(cat_synsets):\n",
        "    wordforms=[l.name() for l in s.lemmas()]\n",
        "    print(\"{}:{}\\n\\t{}\".format(i,wordforms,s.definition()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIZpPnrYx0W2"
      },
      "source": [
        "The `Synset` object also has `hyponyms` and `hypernyms` methods which return hyponym and hypernym synsets respectively.\n",
        "\n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuAnSX4qx0W2",
        "outputId": "2a6d68bc-42ea-4878-fd25-8490eb3a6c2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Synset('card.n.08'), Synset('logbook.n.01'), Synset('won-lost_record.n.01')]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#getting back the list of hyponym synsets for recordn5 (the 5th noun sense of record)\n",
        "recordn5.hyponyms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-ZVHkVUEHMr",
        "outputId": "1331f028-4318-4e16-de33-54a59748b30b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['cheetah', 'chetah', 'Acinonyx_jubatus']:long-legged spotted cat of Africa and southwestern Asia having nonretractile claws; the swiftest mammal; can be trained to run down game\n",
            "['jaguar', 'panther', 'Panthera_onca', 'Felis_onca']:a large spotted feline of tropical America similar to the leopard; in some classifications considered a member of the genus Felis\n",
            "['leopard', 'Panthera_pardus']:large feline of African and Asian forests usually having a tawny coat with black spots\n",
            "['liger']:offspring of a male lion and a female tiger\n",
            "['lion', 'king_of_beasts', 'Panthera_leo']:large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male\n",
            "['saber-toothed_tiger', 'sabertooth']:any of many extinct cats of the Old and New Worlds having long swordlike upper canine teeth; from the Oligocene through the Pleistocene\n",
            "['snow_leopard', 'ounce', 'Panthera_uncia']:large feline of upland central Asia having long thick whitish fur\n",
            "['tiger', 'Panthera_tigris']:large feline of forests in most of Asia having a tawny coat with black stripes; endangered\n",
            "['tiglon', 'tigon']:offspring of a male tiger and a female lion\n"
          ]
        }
      ],
      "source": [
        "#iterating over the hyponyms of the 6th Synset in the list of synsets for cat\n",
        "for h in cat_synsets[6].hyponyms():\n",
        "    h_words=[w.name() for w in h.lemmas()]\n",
        "    print(\"{}:{}\".format(h_words,h.definition()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbrNQMBIEHMr",
        "outputId": "51fffd5a-fe41-47bb-9fa9-75607651ea74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['feline', 'felid']:any of various lithe-bodied roundheaded fissiped mammals, many with retractile claws\n"
          ]
        }
      ],
      "source": [
        "##Iterating over the hypernyms of the 6th sense of cat and output lemma names and definition\n",
        "for h in cat_synsets[6].hypernyms():\n",
        "    h_words=[w.name() for w in h.lemmas()]\n",
        "    print(\"{}:{}\".format(h_words,h.definition()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDr-mGvYEHMr"
      },
      "source": [
        "As an alternative to calling .names() on the Lemmas associated with a Synset, you can also use the .lemma_names() method directly on a synset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luB2TjF6x0W5",
        "outputId": "74235e5a-7ca6-4e4d-b65d-3e43545cbd24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['fact']\n"
          ]
        }
      ],
      "source": [
        "for h in recordn5.hypernyms():\n",
        "  print(h.lemma_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CudFnfA_x0W8"
      },
      "source": [
        "Since the hyponymy relation forms a tree, we would expect synsets to generally have multiple hyponyms and a single hypernym.  At the top of the tree (also called the **root**), the hypernym list will be empty.  Most noun concepts in WordNet share a common root hypernym which is *entity*.  At the bottom of the tree (also referred to as the **leaves** of the tree), the hyponym list will be empty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWssYf-Gx0W9"
      },
      "source": [
        "### Exercise 1.2\n",
        "Write a function, `distance_to_root` that will take a Synset and traverse up the tree until it reaches a root of the tree.  When it does so, it should return the number of steps taken.\n",
        "\n",
        "Hint: This can be done using **recursion**, where a function repeatedly calls itself.  You need to define:\n",
        "* a base case:  How will the function know when it is at the top of the tree and what should it return?\n",
        "* a recursive step: In the general case, the function should call itself with a simpler problem (a Synset which is closer to the top of the tree).  When it gets the result of this function call, it needs to modify it in some way and then return its own answer\n",
        "\n",
        "Make sure you test your function.  You should find that the 5th noun sense of record is 6 steps from the top.\n",
        "\n",
        "How far are all of the other noun sense of book from a root of the tree?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrqQsGUWx0W9",
        "outputId": "20cf3a89-b8d8-41a8-851d-1e0e14c0dd2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['plant', 'works', 'industrial_plant'] 7\n",
            "['plant', 'flora', 'plant_life'] 6\n",
            "Warning: multiple hypernyms\n",
            "['plant'] 7\n",
            "['plant'] 10\n"
          ]
        }
      ],
      "source": [
        "def distance_to_root(asynset):\n",
        "    #print(asynset.lemma_names())\n",
        "    hypernyms=asynset.hypernyms()\n",
        "    if len(hypernyms)==0:\n",
        "        #reached the top and have to stop\n",
        "        return 0\n",
        "    else:\n",
        "        if len(hypernyms)>1:\n",
        "            print(\"Warning: multiple hypernyms\")\n",
        "        return (distance_to_root(hypernyms[0])+1)\n",
        "    \n",
        "for asynset in wn.synsets('plant',wn.NOUN):\n",
        "    print(asynset.lemma_names(),distance_to_root(asynset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zyRTqZgx0XI"
      },
      "source": [
        "## Semantic Similarity in WordNet\n",
        "\n",
        "The simplest way of defining how similar two concepts are according to WordNet is to use the pathlength measure:\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "\\mbox{sim}(\\mbox{synsetA},\\mbox{synsetB})=\\frac{1}{1+\\mbox{lengthOfPath}(\\mbox{synsetA},\\mbox{synsetB})}\n",
        "\\end{eqnarray*}\n",
        "\n",
        "We have also introduced other measures in the lectures which incorporate **information content**, i.e., the amount of information we receive when a word from a given synset is used (there is more information in being told that something is a *poodle* than in being told it is an *animal*).\n",
        "\n",
        "The `nltk.wn` module has built-in functions for computing these similarities between synsets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7IOQRN9x0XJ",
        "outputId": "3a0cec3f-fcbf-475b-cbf5-5ddc0b4aa03b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "path_similarity 0.2\n",
            "resnik_similarity 5.454686565783099\n",
            "lin_similarity 0.7098990245459575\n"
          ]
        }
      ],
      "source": [
        "books=wn.synsets(\"book\",wn.NOUN)\n",
        "print(\"path_similarity {}\".format(wn.path_similarity(books[0],books[1])))\n",
        "\n",
        "brown_ic=wn_ic.ic(\"ic-brown.dat\")  #this gets information content data from the Brown corpus\n",
        "print(\"resnik_similarity {}\".format(wn.res_similarity(books[0],books[1],brown_ic)))\n",
        "print(\"lin_similarity {}\".format(wn.lin_similarity(books[0],books[1],brown_ic)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_KGE06Tx0XM"
      },
      "source": [
        "Note it is impossible to compare synsets of different parts of speech using these methods because they are not connected via hyponymy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "-9c7H_Qdx0XN",
        "outputId": "9c42f099-54bc-42d7-840b-358659910542"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "path_similarity 0.058823529411764705\n"
          ]
        },
        {
          "ename": "WordNetError",
          "evalue": "Computing the least common subsumer requires Synset('book.n.01') and Synset('reserve.v.04') to have the same part of speech.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWordNetError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-552fbfdbf6af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbooksV\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"book\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVERB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path_similarity {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooksN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbooksV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resnik_similarity {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooksN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbooksV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbrown_ic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lin_similarity {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooksN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbooksV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbrown_ic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mres_similarity\u001b[0;34m(self, synset1, synset2, ic, verbose)\u001b[0m\n\u001b[1;32m   1826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1827\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mres_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msynset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynset2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m     \u001b[0mres_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mres_similarity\u001b[0;34m(self, other, ic, verbose)\u001b[0m\n\u001b[1;32m    994\u001b[0m         \"\"\"\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m         \u001b[0mic1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlcs_ic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lcs_ic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlcs_ic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m_lcs_ic\u001b[0;34m(synset1, synset2, ic, verbose)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         raise WordNetError(\n\u001b[1;32m   2159\u001b[0m             \u001b[0;34m\"Computing the least common subsumer requires \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m             \u001b[0;34m\"%s and %s to have the same part of speech.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msynset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m         )\n\u001b[1;32m   2162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mWordNetError\u001b[0m: Computing the least common subsumer requires Synset('book.n.01') and Synset('reserve.v.04') to have the same part of speech."
          ]
        }
      ],
      "source": [
        "booksN=wn.synsets(\"book\",wn.NOUN)\n",
        "booksV=wn.synsets(\"book\",wn.VERB)\n",
        "print(\"path_similarity {}\".format(wn.path_similarity(booksN[0],booksV[1])))\n",
        "print(\"resnik_similarity {}\".format(wn.res_similarity(booksN[0],booksV[1],brown_ic)))\n",
        "print(\"lin_similarity {}\".format(wn.lin_similarity(booksN[0],booksV[1],brown_ic)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OZSCQQZx0XP"
      },
      "source": [
        "### Exercise 2.1\n",
        "\n",
        "The similarity of two **words** with a given part of speech is defined as the **maximum** similarity of all possible sense pairings.  If word A has 5 noun senses and word B has 4 noun senses than there are 20 possible sense pairings to check.\n",
        "\n",
        "* Write a function which will compute the path_similarity of two nouns.\n",
        "* Make sure you test it.  The correct answer for *chicken* and *car* is 0.0909 to 3SF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPt2ZM2Bx0XQ",
        "outputId": "df93fa36-f8d0-4065-a5ea-271f0e8b0f83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.09090909090909091"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def path_similarity(wordA,wordB,pos=wn.NOUN):\n",
        "    synsetsA=wn.synsets(wordA,pos)\n",
        "    synsetsB=wn.synsets(wordB,pos)\n",
        "    maxsofar=0\n",
        "    for synsetA in synsetsA:\n",
        "        for synsetB in synsetsB:\n",
        "            sim=wn.path_similarity(synsetA,synsetB)\n",
        "            if sim>maxsofar:\n",
        "                maxsofar=sim\n",
        "    return maxsofar\n",
        "\n",
        "path_similarity(\"chicken\",\"car\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9PDsl7vx0XT"
      },
      "source": [
        "### Exercise 2.2\n",
        "Generalise your path_similarity function so that it takes an extra optional argument:\n",
        "* the similarity measure to use\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN1w-Qpbx0XT"
      },
      "outputs": [],
      "source": [
        "def word_similarity(wordA,wordB,pos=wn.NOUN,measure=\"path\"):\n",
        "    synsetsA=wn.synsets(wordA,pos)\n",
        "    synsetsB=wn.synsets(wordB,pos)\n",
        "    maxsofar=0\n",
        "    brown_ic=wn_ic.ic(\"ic-brown.dat\")\n",
        "    for synsetA in synsetsA:\n",
        "        for synsetB in synsetsB:\n",
        "            if measure==\"path\":\n",
        "                sim=wn.path_similarity(synsetA,synsetB)\n",
        "            elif measure==\"res\":\n",
        "                sim=wn.res_similarity(synsetA,synsetB,brown_ic)\n",
        "            elif measure==\"lin\":\n",
        "                sim=wn.lin_similarity(synsetA,synsetB,brown_ic)\n",
        "            \n",
        "            if sim>maxsofar:\n",
        "                maxsofar=sim\n",
        "    return maxsofar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVYBNfT_x0XX",
        "outputId": "b946babb-1133-477b-903e-b029566e8dcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.17900106582025765"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_similarity(\"chicken\",\"car\",measure=\"lin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OJGUbmwx0Xa"
      },
      "source": [
        "## Comparing WordNet Similarities with Human Synonymy Judgements\n",
        "\n",
        "The file `mcdata.csv` contains human synonymy judgements for a list of 30 noun pairs.   We can read in a `.csv` file using the `csv` library "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKC0iTVOx0Xb"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "directory='/content/drive/My Drive/NLE Notebooks/Week5LabsSolutions/'\n",
        "filename='mcdata.csv'\n",
        "filepath=os.path.join(directory,filename)\n",
        "\n",
        "\n",
        "with open(filename,'r') as filestream:\n",
        "    mcdata=list(csv.reader(filestream,delimiter=','))\n",
        "\n",
        "df=pd.DataFrame(mcdata,columns=[\"word1\",\"word2\",\"human similarity\"])\n",
        "#lets make sure the scores are floats not strings.  We can do this by applying the float() function to every value in the column (which we can using map)\n",
        "df[\"human similarity\"]=df[\"human similarity\"].map(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33m9OEQ5EHMu",
        "outputId": "fb22478d-f0ed-48d8-e5b0-7168c46837d8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>human similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>30.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.929000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.419979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.682500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.670000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.342500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.920000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       human similarity\n",
              "count         30.000000\n",
              "mean           1.929000\n",
              "std            1.419979\n",
              "min            0.080000\n",
              "25%            0.682500\n",
              "50%            1.670000\n",
              "75%            3.342500\n",
              "max            3.920000"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YdzQ023x0Xe"
      },
      "source": [
        "Note that the human similarity judgements range between 0 and 4.\n",
        "\n",
        "### Exercise 3.1\n",
        "Write code that will \n",
        "* compute the WordNet path_similarity for every pair of words in this data; and\n",
        "* add it as a column in the dataframe.  If you have the path similarity scores in a list called `scores`, you can do this using `df['path']=scores`\n",
        "\n",
        "Repeat for the Resnik and Lin similarity scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "id": "NahtYzofx0Xe",
        "outputId": "3b33efcb-1f92-4331-a45c-aa4965669344"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word1</th>\n",
              "      <th>word2</th>\n",
              "      <th>human similarity</th>\n",
              "      <th>path</th>\n",
              "      <th>res</th>\n",
              "      <th>lin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>asylum</td>\n",
              "      <td>madhouse</td>\n",
              "      <td>3.61</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>9.475167</td>\n",
              "      <td>0.855584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bird</td>\n",
              "      <td>cock</td>\n",
              "      <td>3.05</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>7.677755</td>\n",
              "      <td>0.773937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bird</td>\n",
              "      <td>crane</td>\n",
              "      <td>2.97</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>7.677755</td>\n",
              "      <td>0.747812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>boy</td>\n",
              "      <td>lad</td>\n",
              "      <td>3.76</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>8.399492</td>\n",
              "      <td>0.830562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>brother</td>\n",
              "      <td>monk</td>\n",
              "      <td>2.82</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>9.261593</td>\n",
              "      <td>0.986407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>car</td>\n",
              "      <td>automobile</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.591401</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>cemetery</td>\n",
              "      <td>woodland</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>1.290026</td>\n",
              "      <td>0.123441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>chord</td>\n",
              "      <td>smile</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>2.619644</td>\n",
              "      <td>0.246256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>coast</td>\n",
              "      <td>forest</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1.290026</td>\n",
              "      <td>0.130646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>coast</td>\n",
              "      <td>hill</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>5.884681</td>\n",
              "      <td>0.599113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>coast</td>\n",
              "      <td>shore</td>\n",
              "      <td>3.70</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>9.415744</td>\n",
              "      <td>0.963217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>crane</td>\n",
              "      <td>implement</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>3.257679</td>\n",
              "      <td>0.359057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>food</td>\n",
              "      <td>fruit</td>\n",
              "      <td>3.08</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.592755</td>\n",
              "      <td>0.160984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>food</td>\n",
              "      <td>rooster</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.801759</td>\n",
              "      <td>0.091932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>forest</td>\n",
              "      <td>graveyard</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>1.290026</td>\n",
              "      <td>0.123441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>furnace</td>\n",
              "      <td>stove</td>\n",
              "      <td>3.11</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>2.305849</td>\n",
              "      <td>0.228138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>gem</td>\n",
              "      <td>jewel</td>\n",
              "      <td>3.84</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.067705</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>glass</td>\n",
              "      <td>magician</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>2.282647</td>\n",
              "      <td>0.214168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>journey</td>\n",
              "      <td>car</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>journey</td>\n",
              "      <td>voyage</td>\n",
              "      <td>3.84</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>6.825958</td>\n",
              "      <td>0.777715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>lad</td>\n",
              "      <td>brother</td>\n",
              "      <td>1.66</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.333545</td>\n",
              "      <td>0.255175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>lad</td>\n",
              "      <td>wizard</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.333545</td>\n",
              "      <td>0.255091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>magician</td>\n",
              "      <td>wizard</td>\n",
              "      <td>3.50</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.980693</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>midday</td>\n",
              "      <td>noon</td>\n",
              "      <td>3.42</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.064403</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>monk</td>\n",
              "      <td>oracle</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>2.333545</td>\n",
              "      <td>0.225652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>monk</td>\n",
              "      <td>slave</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.333545</td>\n",
              "      <td>0.254311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>noon</td>\n",
              "      <td>string</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.596229</td>\n",
              "      <td>0.066172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>rooster</td>\n",
              "      <td>voyage</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>shore</td>\n",
              "      <td>woodland</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>1.290026</td>\n",
              "      <td>0.135583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>tool</td>\n",
              "      <td>implement</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>5.877389</td>\n",
              "      <td>0.947154</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       word1       word2  human similarity      path        res       lin\n",
              "0     asylum    madhouse              3.61  0.500000   9.475167  0.855584\n",
              "1       bird        cock              3.05  0.500000   7.677755  0.773937\n",
              "2       bird       crane              2.97  0.250000   7.677755  0.747812\n",
              "3        boy         lad              3.76  0.500000   8.399492  0.830562\n",
              "4    brother        monk              2.82  0.500000   9.261593  0.986407\n",
              "5        car  automobile              3.92  1.000000   7.591401  1.000000\n",
              "6   cemetery    woodland              0.95  0.111111   1.290026  0.123441\n",
              "7      chord       smile              0.13  0.090909   2.619644  0.246256\n",
              "8      coast      forest              0.42  0.166667   1.290026  0.130646\n",
              "9      coast        hill              0.87  0.200000   5.884681  0.599113\n",
              "10     coast       shore              3.70  0.500000   9.415744  0.963217\n",
              "11     crane   implement              1.68  0.200000   3.257679  0.359057\n",
              "12      food       fruit              3.08  0.100000   1.592755  0.160984\n",
              "13      food     rooster              0.89  0.062500   0.801759  0.091932\n",
              "14    forest   graveyard              0.84  0.111111   1.290026  0.123441\n",
              "15   furnace       stove              3.11  0.100000   2.305849  0.228138\n",
              "16       gem       jewel              3.84  1.000000  12.067705  1.000000\n",
              "17     glass    magician              0.11  0.125000   2.282647  0.214168\n",
              "18   journey         car              1.16  0.055556   0.000000  0.000000\n",
              "19   journey      voyage              3.84  0.500000   6.825958  0.777715\n",
              "20       lad     brother              1.66  0.200000   2.333545  0.255175\n",
              "21       lad      wizard              0.42  0.200000   2.333545  0.255091\n",
              "22  magician      wizard              3.50  1.000000  11.980693  1.000000\n",
              "23    midday        noon              3.42  1.000000  11.064403  1.000000\n",
              "24      monk      oracle              1.10  0.125000   2.333545  0.225652\n",
              "25      monk       slave              0.55  0.200000   2.333545  0.254311\n",
              "26      noon      string              0.08  0.083333   0.596229  0.066172\n",
              "27   rooster      voyage              0.08  0.041667   0.000000  0.000000\n",
              "28     shore    woodland              0.63  0.200000   1.290026  0.135583\n",
              "29      tool   implement              1.68  0.500000   5.877389  0.947154"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "measures=[\"path\",\"res\",\"lin\"]\n",
        "for measure in measures:\n",
        "    scores=[]\n",
        "\n",
        "    for triple in mcdata:\n",
        "        scores.append(word_similarity(triple[0],triple[1],measure=measure))\n",
        "    df[measure]=scores\n",
        "    \n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YVoa9A7x0Xk"
      },
      "source": [
        "We can use pandas functionality to produce scatter plots and examine the correlation between different variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "jUJzNFiqx0Xl",
        "outputId": "352675db-c6ee-4683-e674-3b58b9dae838"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='human similarity', ylabel='path'>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "x=\"human similarity\"\n",
        "y=\"path\"\n",
        "\n",
        "df.plot.scatter(x,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlFZwzqjx0Xp"
      },
      "source": [
        "### Exercise 3.2\n",
        "Generate scatter plots showing Resnik similarity against human similarity and Lin similarity against human similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "yISMpAd-x0Xr",
        "outputId": "bb641055-0c7b-42fd-a79e-8e12a167540e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='human similarity', ylabel='res'>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.plot.scatter(\"human similarity\",\"res\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "oTaqyFdQx0Xu",
        "outputId": "2b5c94c8-3703-4d80-ee25-2355445be583"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='human similarity', ylabel='lin'>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.plot.scatter(\"human similarity\",\"lin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-GNK8DAx0X7"
      },
      "source": [
        "The `DataFrame.corr()` method will compute the correlation for all pairs of columns with numeric values.  It is better to use Spearman's rank correlation coefficient than Pearson's product-moment correlation coefficient, since similarity scores are unlikely to be normally distributed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "_NAOCoUOx0X8",
        "outputId": "da106af2-adba-40f8-990d-d3a8f347a1f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>human similarity</th>\n",
              "      <th>path</th>\n",
              "      <th>res</th>\n",
              "      <th>lin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>human similarity</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.722743</td>\n",
              "      <td>0.735945</td>\n",
              "      <td>0.753510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>path</th>\n",
              "      <td>0.722743</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.900648</td>\n",
              "      <td>0.945509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>res</th>\n",
              "      <td>0.735945</td>\n",
              "      <td>0.900648</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.962707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lin</th>\n",
              "      <td>0.753510</td>\n",
              "      <td>0.945509</td>\n",
              "      <td>0.962707</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  human similarity      path       res       lin\n",
              "human similarity          1.000000  0.722743  0.735945  0.753510\n",
              "path                      0.722743  1.000000  0.900648  0.945509\n",
              "res                       0.735945  0.900648  1.000000  0.962707\n",
              "lin                       0.753510  0.945509  0.962707  1.000000"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.corr(method='spearman')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORzNGby0x0YH"
      },
      "source": [
        "### Exercise 3.3\n",
        "* Looking at the scatter plots and the correlation coefficients, what do you conclude about the different WordNet similarity measures?\n",
        "* Do you have any reservations about your conclusions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Wbpkgtbx0YJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}