{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pq7c607fjXsS"
   },
   "source": [
    "# Week 2: Preprocessing Text (Part 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1366,
     "status": "ok",
     "timestamp": 1600522870753,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "vo-uSUEwjXsU",
    "outputId": "7fabd696-4862-490a-e3d7-fd530627cea3"
   },
   "outputs": [],
   "source": [
    "#necessary library imports and setup introduced previously\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "from itertools import zip_longest\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baDBuSxYlE0Q"
   },
   "outputs": [],
   "source": [
    "##uncomment these lines below if working on colab\n",
    "#from google.colab import drive\n",
    "##mount google drive\n",
    "#drive.mount('/content/drive/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-7FNGNyljXsY"
   },
   "source": [
    "## Overview \n",
    "Remember, a raw text document is just a sequence of characters. There are a number of basic steps that are often performed when processing natural language text. In lab sessions this week we are covering some of the basic text pre-processing methods. In the previous notebook, you looked at\n",
    "- <b> segmentation</b> - breaking down large units of text into smaller units such as documents and sentences. \n",
    "- <b> tokenisation</b> - roughly speaking, this involves grouping characters into words;\n",
    "\n",
    "In this notebook, you will be looking at:\n",
    "- <b>case normalisation</b> - this involves converting all of the text into lower case; \n",
    "- <b>stemming</b> - this involves removing a word's inflections to find the stem; and \n",
    "- <b>punctuation and stop-word removal</b> - stop-words are common functions words that in some situations can be ignored.\n",
    "\n",
    "Note that we do not always apply all of the above preprocessing methods; it depends on the application. One of the things that you will be learning about in this module, is when the application of each of these methods is, and is not, appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7l6pjAZljXsY"
   },
   "source": [
    "## Normalising text and removing unimportant tokens\n",
    "In this next section we will consider several methods that pre-process (tokenised) text in ways that are sometimes helpful to 'downstream' processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CQbWxHPFjXsZ"
   },
   "source": [
    "### Number and case normalisation\n",
    "Without any kind of normalisation, the tokens `\"help\"` and `\"Help\"` are two distinct types. In some contexts you may not want to distinguish them.\n",
    "\n",
    "Another example, is that `\"1998\"` and `\"1999\"` count as distinct types. There are situations where there is no need to distinction between different numbers.\n",
    "\n",
    "The following code performs case normalisation and replaces tokens that consist of digits by \"NUM\". \n",
    "- Python provides a [number of functions](http://docs.python.org/library/stdtypes.html#string-methods), which you can call in order to analyse their content, or produce new strings from them.\n",
    "- The code uses a [list comprehension](http://docs.python.org/tutorial/datastructures.html#list-comprehensions) to build a new list by looping through and filtering items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 654,
     "status": "ok",
     "timestamp": 1600522440787,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "GGESwOoSjXsZ",
    "outputId": "55762d04-f87e-45b0-c768-fb5bdb1aeba5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'cake', 'is', 'a', 'lie']\n",
      "['in', 'the', 'year', 'NUM', 'of', 'the', 'fourth', 'age', ',', 'after', 'NUM', 'years', 'as', 'king', ',', 'aragorn', 'died', 'at', 'the', 'age', 'of', 'NUM']\n"
     ]
    }
   ],
   "source": [
    "tokens = [\"The\",\"cake\",\"is\",\"a\",\"LIE\"]      #a list of tokens, some of which contain uppercase letters\n",
    "print([token.lower() for token in tokens])   #print newly created list of all lowercase tokens\n",
    "\n",
    "numbers = ['in', 'the', 'year', '120', 'of', 'the', 'fourth', 'age', ',', 'after', '120', 'years', 'as', 'king', ',' , 'aragorn', 'died', 'at', 'the', 'age', 'of', '210']\n",
    "print([\"NUM\" if token.isdigit() else token for token in numbers])  #replace all number tokens with \"NUM\" in a new list of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4uE15AXjXsc"
   },
   "source": [
    "### Exercise 1.1\n",
    "- Write a function <code>number_normalise</code> which \n",
    "    * replaces numbers with NUM; \n",
    "    * and replaces tokens such as `\"4th\"`, `\"1st\"` and `\"22nd\"` with `\"Nth\"`.\n",
    "- Test your code on the list `[\"Within\",\"5\",\"minutes\",\",\",\"the\", \"1st\", \"and\", \"2nd\", \"placed\", \"runners\", \"lapped\", \"the\", \"5th\",\".\"]`. \n",
    "- Check that the token `\"and\"` isn't changed to `\"Nth\"`.\n",
    "- You will find [this page](http://docs.python.org/library/stdtypes.html#string-methods) useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 654,
     "status": "ok",
     "timestamp": 1600522469260,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "62J_VD4GjXsd",
    "outputId": "9f7b3e32-10c1-409a-9277-d662b3470cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Within', 'NUM', 'minutes', ',', 'the', 'Nth', 'and', 'Nth', 'placed', 'runners', 'lapped', 'the', 'Nth', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = [\"Within\",\"5\",\"minutes\",\",\",\"the\", \"1st\", \"and\", \"2nd\", \"placed\", \"runners\", \"lapped\", \"the\", \"5th\",\".\"]\n",
    "def number_normalise(tokens):\n",
    "    normalised=[\"Nth\" if (token.endswith((\"nd\",\"st\",\"th\")) and token[:-2].isdigit()) else token for token in tokens]\n",
    "    normalised=[\"NUM\" if token.isdigit() else token for token in normalised]\n",
    "    return normalised\n",
    "\n",
    "print(number_normalise(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pqGsM4K0jXsf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eTBYKFVVjXsj"
   },
   "source": [
    "### Exercise 1.2\n",
    "- Complete the code in the cell below. You have just two lines to complete. The goal is to use a large sample of the Reuters corpus to establish the extent to which vocabulary size is reduced when number and case normalisation is applied.\n",
    "- For each of the two incomplete lines you should ideally use nested list comprehensions. This is described in Section 5.1.4 in [this document](http://docs.python.org/tutorial/datastructures.html#list-comprehensions).  Alternatively, you could define functions which iterate over the sentences in each sample and the tokens within each sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEtQ39z_nEGm"
   },
   "outputs": [],
   "source": [
    "#the sample_sentences() function from the last lab will be useful here\n",
    "#next week we will look at including useful functions like this in a utils python file which we can import from\n",
    "import random\n",
    "\n",
    "def sample_sentences(corpus,sample_size):\n",
    "    \n",
    "    size=len(corpus)\n",
    "    ids=random.sample(range(size),sample_size) \n",
    "    sample=[corpus[i] for i in ids]  \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qePwmgrnjXsk"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-8efe6d4b2586>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-8efe6d4b2586>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    lowered_sentences = # complete this line\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def vocabulary_size(sentences):\n",
    "    tok_counts = {}\n",
    "    for sentence in sentences: \n",
    "        for token in sentence:\n",
    "            tok_counts[token]=tok_counts.get(token,0)+1\n",
    "    return len(tok_counts.keys())\n",
    "\n",
    "  \n",
    "\n",
    "sample_size = 10000\n",
    "\n",
    "raw_sentences = sample_sentences(reuters.sents(),sample_size)\n",
    "\n",
    "############################################\n",
    "lowered_sentences = # complete this line\n",
    "normalised_sentences = # complete this line\n",
    "\n",
    "############################################\n",
    "\n",
    "raw_vocab_size = vocabulary_size(tokenised_sentences)\n",
    "normalised_vocab_size = vocabulary_size(normalised_sentences)\n",
    "print(\"Normalisation produced a {0:.2f}% reduction in vocabulary size from {1} to {2}\".format(\n",
    "    100*(raw_vocab_size - normalised_vocab_size)/raw_vocab_size,raw_vocab_size,normalised_vocab_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4807,
     "status": "ok",
     "timestamp": 1600522643248,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "OozqCpzQjXsn",
    "outputId": "c652917b-4da3-41cc-ab69-8f455b8146dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bass', 'group', 'cuts', 'national', 'distillers', '&', 'lt', ';', 'dr', '>', 'stake', 'an', 'investor', 'group', 'led', 'by', 'members', 'of', 'the', 'bass', 'family', 'of', 'fort', 'worth', ',', 'texas', ',', 'said', 'it', 'lowered', 'its', 'stake', 'in', 'national', 'distillers', 'and', 'chemical', 'corp', 'to', '1', ',', '159', ',', '400', 'shares', ',', 'or', '3', '.', '6', 'pct', 'of', 'the', 'total', 'common', ',', 'from', '1', ',', '727', ',', '200', ',', 'or', '5', '.', '3', 'pct', '.']\n",
      "['bass', 'group', 'cuts', 'national', 'distillers', '&', 'lt', ';', 'dr', '>', 'stake', 'an', 'investor', 'group', 'led', 'by', 'members', 'of', 'the', 'bass', 'family', 'of', 'fort', 'worth', ',', 'texas', ',', 'said', 'it', 'lowered', 'its', 'stake', 'in', 'national', 'distillers', 'and', 'chemical', 'corp', 'to', 'NUM', ',', 'NUM', ',', 'NUM', 'shares', ',', 'or', 'NUM', '.', 'NUM', 'pct', 'of', 'the', 'total', 'common', ',', 'from', 'NUM', ',', 'NUM', ',', 'NUM', ',', 'or', 'NUM', '.', 'NUM', 'pct', '.']\n",
      "Normalisation produced a 28.60% reduction in vocabulary size from 19919 to 14222\n"
     ]
    }
   ],
   "source": [
    "def vocabulary_size(sentences):\n",
    "    tok_counts = {}\n",
    "    for sentence in sentences: \n",
    "        for token in sentence:\n",
    "            tok_counts[token]=tok_counts.get(token,0)+1\n",
    "    return len(tok_counts.keys())\n",
    "    \n",
    "\n",
    "sample_size = 10000\n",
    "\n",
    "raw_sentences = sample_sentences(reuters.sents(),sample_size)\n",
    "\n",
    "############################################\n",
    "lowered_sentences = [[word.lower() for word in sentence] for sentence in raw_sentences]\n",
    "normalised_sentences = [number_normalise(sentence) for sentence in lowered_sentences]\n",
    "print(lowered_sentences[0])\n",
    "print(normalised_sentences[0])\n",
    "############################################\n",
    "\n",
    "raw_vocab_size = vocabulary_size(raw_sentences)\n",
    "normalised_vocab_size = vocabulary_size(normalised_sentences)\n",
    "print(\"Normalisation produced a {0:.2f}% reduction in vocabulary size from {1} to {2}\".format(\n",
    "    100*(raw_vocab_size - normalised_vocab_size)/raw_vocab_size,raw_vocab_size,normalised_vocab_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sXE01afsjXsq"
   },
   "source": [
    "## Stemming\n",
    "A considerable amount of the lexical variation found in documents results from the use of morphological variants which we might not wish to distinguish - e.g. when determining the topic of a document. An easy way to remove these varied forms is to use a stemmer. NLTK includes a number of stemmers in the `nltk.stem` package.\n",
    "- [NLTK stem module API](http://nltk.org/api/nltk.stem.html)\n",
    "\n",
    "- [NLTK Porter stemmer](http://nltk.org/api/nltk.stem.html?highlight=stemmer#nltk.stem.porter.PorterStemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYvUBOUnjXsr"
   },
   "source": [
    "- Look at the code below to show how the NLTK implementation of the Porter stemmer in `nltk.stem.porter.PorterStemmer` stems a sample of sentences in the Reuters corpus.\n",
    "- Have a close look at the differences between the columns. This will give you a good indication of what the stemmer does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3647,
     "status": "ok",
     "timestamp": 1600522738115,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "RLMKMiU3jXsr",
    "outputId": "e45b14ec-7b02-45e3-d887-e424b8dc2098"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rice</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hall</td>\n",
       "      <td>hall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>manages</td>\n",
       "      <td>manag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>investments</td>\n",
       "      <td>invest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>institutions</td>\n",
       "      <td>institut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>individuals</td>\n",
       "      <td>individu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>has</td>\n",
       "      <td>ha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>about</td>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>690</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mln</td>\n",
       "      <td>mln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dlrs</td>\n",
       "      <td>dlr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>assets</td>\n",
       "      <td>asset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>under</td>\n",
       "      <td>under</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>management</td>\n",
       "      <td>manag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>currently</td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BEFORE     AFTER\n",
       "0             It        it\n",
       "1           said      said\n",
       "2           Rice      rice\n",
       "3           Hall      hall\n",
       "4        manages     manag\n",
       "5    investments    invest\n",
       "6            for       for\n",
       "7   institutions  institut\n",
       "8            and       and\n",
       "9    individuals  individu\n",
       "10           and       and\n",
       "11           has        ha\n",
       "12         about     about\n",
       "13           690       690\n",
       "14           mln       mln\n",
       "15          dlrs       dlr\n",
       "16            in        in\n",
       "17        assets     asset\n",
       "18         under     under\n",
       "19    management     manag\n",
       "20     currently   current\n",
       "21             .         ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iran</td>\n",
       "      <td>iran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>against</td>\n",
       "      <td>against</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>States</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vessels</td>\n",
       "      <td>vessel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gulf</td>\n",
       "      <td>gulf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>,\"</td>\n",
       "      <td>,\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Walters</td>\n",
       "      <td>walter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BEFORE    AFTER\n",
       "0      Iran     iran\n",
       "1   against  against\n",
       "2    United     unit\n",
       "3    States    state\n",
       "4   vessels   vessel\n",
       "5        in       in\n",
       "6       the      the\n",
       "7      Gulf     gulf\n",
       "8        ,\"       ,\"\n",
       "9   Walters   walter\n",
       "10     said     said\n",
       "11        .        ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>budget</td>\n",
       "      <td>budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deficit</td>\n",
       "      <td>deficit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>has</td>\n",
       "      <td>ha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meant</td>\n",
       "      <td>meant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>buying</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>more</td>\n",
       "      <td>more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>imports</td>\n",
       "      <td>import</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BEFORE    AFTER\n",
       "0      That     that\n",
       "1    budget   budget\n",
       "2   deficit  deficit\n",
       "3       has       ha\n",
       "4     meant    meant\n",
       "5      that     that\n",
       "6       the      the\n",
       "7         U        u\n",
       "8         .        .\n",
       "9         S        s\n",
       "10        .        .\n",
       "11       Is       is\n",
       "12   buying      buy\n",
       "13     more     more\n",
       "14  imports   import\n",
       "15        .        ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Widdrington</td>\n",
       "      <td>widdrington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Labatt</td>\n",
       "      <td>labatt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>three</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>year</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>business</td>\n",
       "      <td>busi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>plan</td>\n",
       "      <td>plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>now</td>\n",
       "      <td>now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>being</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>updated</td>\n",
       "      <td>updat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>targets</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>total</td>\n",
       "      <td>total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sales</td>\n",
       "      <td>sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>about</td>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>six</td>\n",
       "      <td>six</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>billion</td>\n",
       "      <td>billion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dlrs</td>\n",
       "      <td>dlr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>including</td>\n",
       "      <td>includ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>billion</td>\n",
       "      <td>billion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>dlrs</td>\n",
       "      <td>dlr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>U</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Labatt</td>\n",
       "      <td>labatt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Canada</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>'</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>leading</td>\n",
       "      <td>lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>brewer</td>\n",
       "      <td>brewer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>has</td>\n",
       "      <td>ha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>expanded</td>\n",
       "      <td>expand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>U</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>food</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>products</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>industry</td>\n",
       "      <td>industri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>acquisitions</td>\n",
       "      <td>acquisit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BEFORE        AFTER\n",
       "0    Widdrington  widdrington\n",
       "1           said         said\n",
       "2         Labatt       labatt\n",
       "3              '            '\n",
       "4              s            s\n",
       "5          three        three\n",
       "6              -            -\n",
       "7           year         year\n",
       "8       business         busi\n",
       "9           plan         plan\n",
       "10             ,            ,\n",
       "11           now          now\n",
       "12         being           be\n",
       "13       updated        updat\n",
       "14             ,            ,\n",
       "15       targets       target\n",
       "16         total        total\n",
       "17         sales         sale\n",
       "18            of           of\n",
       "19         about        about\n",
       "20           six          six\n",
       "21       billion      billion\n",
       "22          dlrs          dlr\n",
       "23             ,            ,\n",
       "24     including       includ\n",
       "25             2            2\n",
       "26             .            .\n",
       "27            50           50\n",
       "28       billion      billion\n",
       "29          dlrs          dlr\n",
       "30            in           in\n",
       "31           the          the\n",
       "32             U            u\n",
       "33             .            .\n",
       "34             S            s\n",
       "35             .            .\n",
       "36        Labatt       labatt\n",
       "37             ,            ,\n",
       "38        Canada       canada\n",
       "39             '            '\n",
       "40             s            s\n",
       "41       leading         lead\n",
       "42        brewer       brewer\n",
       "43             ,            ,\n",
       "44           has           ha\n",
       "45      expanded       expand\n",
       "46            in           in\n",
       "47           the          the\n",
       "48             U            u\n",
       "49             .            .\n",
       "50             S            s\n",
       "51             .            .\n",
       "52          food         food\n",
       "53      products      product\n",
       "54      industry     industri\n",
       "55            by           by\n",
       "56  acquisitions     acquisit\n",
       "57             .            ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facility</td>\n",
       "      <td>facil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lower</td>\n",
       "      <td>lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>labor</td>\n",
       "      <td>labor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mill</td>\n",
       "      <td>mill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>costs</td>\n",
       "      <td>cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>enhance</td>\n",
       "      <td>enhanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>product</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>quality</td>\n",
       "      <td>qualiti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>range</td>\n",
       "      <td>rang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Slater</td>\n",
       "      <td>slater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BEFORE    AFTER\n",
       "0        The      the\n",
       "1        new      new\n",
       "2   facility    facil\n",
       "3       will     will\n",
       "4      lower    lower\n",
       "5      labor    labor\n",
       "6        and      and\n",
       "7       mill     mill\n",
       "8      costs     cost\n",
       "9        and      and\n",
       "10   enhance   enhanc\n",
       "11   product  product\n",
       "12   quality  qualiti\n",
       "13       and      and\n",
       "14     range     rang\n",
       "15         ,        ,\n",
       "16    Slater   slater\n",
       "17      said     said\n",
       "18         .        ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abe</td>\n",
       "      <td>abe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>visit</td>\n",
       "      <td>visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>prepare</td>\n",
       "      <td>prepar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Prime</td>\n",
       "      <td>prime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Minister</td>\n",
       "      <td>minist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Yasuhiro</td>\n",
       "      <td>yasuhiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nakasone</td>\n",
       "      <td>nakason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>talks</td>\n",
       "      <td>talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>President</td>\n",
       "      <td>presid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ronald</td>\n",
       "      <td>ronald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Reagan</td>\n",
       "      <td>reagan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>later</td>\n",
       "      <td>later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>this</td>\n",
       "      <td>thi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>month</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BEFORE     AFTER\n",
       "0         Abe       abe\n",
       "1           '         '\n",
       "2           s         s\n",
       "3       visit     visit\n",
       "4          is        is\n",
       "5          to        to\n",
       "6     prepare    prepar\n",
       "7         for       for\n",
       "8       Prime     prime\n",
       "9    Minister    minist\n",
       "10   Yasuhiro  yasuhiro\n",
       "11   Nakasone   nakason\n",
       "12          '         '\n",
       "13          s         s\n",
       "14      talks      talk\n",
       "15       with      with\n",
       "16  President    presid\n",
       "17     Ronald    ronald\n",
       "18     Reagan    reagan\n",
       "19      later     later\n",
       "20       this       thi\n",
       "21      month     month\n",
       "22          .         ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taiwan</td>\n",
       "      <td>taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surplus</td>\n",
       "      <td>surplu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>U</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hit</td>\n",
       "      <td>hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>record</td>\n",
       "      <td>record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>billion</td>\n",
       "      <td>billion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>U</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dlrs</td>\n",
       "      <td>dlr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1986</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BEFORE    AFTER\n",
       "0    Taiwan   taiwan\n",
       "1         '        '\n",
       "2         s        s\n",
       "3   surplus   surplu\n",
       "4      with     with\n",
       "5       the      the\n",
       "6         U        u\n",
       "7         .        .\n",
       "8         S        s\n",
       "9         .        .\n",
       "10      Hit      hit\n",
       "11        a        a\n",
       "12   record   record\n",
       "13       13       13\n",
       "14        .        .\n",
       "15        6        6\n",
       "16  billion  billion\n",
       "17        U        u\n",
       "18        .        .\n",
       "19        S        s\n",
       "20        .        .\n",
       "21     Dlrs      dlr\n",
       "22       in       in\n",
       "23     1986     1986\n",
       "24        .        ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bretz</td>\n",
       "      <td>bretz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sharp</td>\n",
       "      <td>sharp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rise</td>\n",
       "      <td>rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>growth</td>\n",
       "      <td>growth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>new</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>orders</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>March</td>\n",
       "      <td>march</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>assures</td>\n",
       "      <td>assur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>beginning</td>\n",
       "      <td>begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>second</td>\n",
       "      <td>second</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>quarter</td>\n",
       "      <td>quarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BEFORE    AFTER\n",
       "0       Bretz    bretz\n",
       "1        said     said\n",
       "2         the      the\n",
       "3       sharp    sharp\n",
       "4        rise     rise\n",
       "5          in       in\n",
       "6         the      the\n",
       "7      growth   growth\n",
       "8          of       of\n",
       "9         new      new\n",
       "10     orders    order\n",
       "11         in       in\n",
       "12      March    march\n",
       "13    assures    assur\n",
       "14          a        a\n",
       "15       good     good\n",
       "16  beginning    begin\n",
       "17        for      for\n",
       "18        the      the\n",
       "19     second   second\n",
       "20    quarter  quarter\n",
       "21          .        ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>firms</td>\n",
       "      <td>firm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apply</td>\n",
       "      <td>appli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>form</td>\n",
       "      <td>form</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cartel</td>\n",
       "      <td>cartel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ministry</td>\n",
       "      <td>ministri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>International</td>\n",
       "      <td>intern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Trade</td>\n",
       "      <td>trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Industry</td>\n",
       "      <td>industri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>today</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>approval</td>\n",
       "      <td>approv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>expected</td>\n",
       "      <td>expect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>later</td>\n",
       "      <td>later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>this</td>\n",
       "      <td>thi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>month</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>officials</td>\n",
       "      <td>offici</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BEFORE     AFTER\n",
       "0             The       the\n",
       "1           firms      firm\n",
       "2            will      will\n",
       "3           apply     appli\n",
       "4              to        to\n",
       "5            form      form\n",
       "6             the       the\n",
       "7          cartel    cartel\n",
       "8              to        to\n",
       "9             the       the\n",
       "10       Ministry  ministri\n",
       "11             of        of\n",
       "12  International    intern\n",
       "13          Trade     trade\n",
       "14            and       and\n",
       "15       Industry  industri\n",
       "16          today     today\n",
       "17            and       and\n",
       "18       approval    approv\n",
       "19             is        is\n",
       "20       expected    expect\n",
       "21          later     later\n",
       "22           this       thi\n",
       "23          month     month\n",
       "24              ,         ,\n",
       "25            the       the\n",
       "26      officials    offici\n",
       "27           said      said\n",
       "28              .         ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Staley</td>\n",
       "      <td>staley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Archer</td>\n",
       "      <td>archer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daniels</td>\n",
       "      <td>daniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Midland</td>\n",
       "      <td>midland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>soon</td>\n",
       "      <td>soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BEFORE    AFTER\n",
       "0   Staley   staley\n",
       "1      and      and\n",
       "2   Archer   archer\n",
       "3  Daniels   daniel\n",
       "4  Midland  midland\n",
       "5     soon     soon\n",
       "6        .        ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    " \n",
    "st = PorterStemmer()\n",
    "\n",
    "sample_size = 10\n",
    "\n",
    "tokenised_sentences = sample_sentences(reuters.sents(),sample_size)\n",
    "\n",
    "for sentence in tokenised_sentences:\n",
    "  df = pd.DataFrame(list(zip_longest(sentence,[st.stem(token) for token in sentence])),columns=[\"BEFORE\",\"AFTER\"])\n",
    "  display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZaBir7EVjXsw"
   },
   "source": [
    "### Exercise 2.1\n",
    "- By looking at the impact on a large sample of the Reuters corpus, establish the extent to which vocabulary size is reduced by stemming.\n",
    "- Write code to do this in the empty cell below. You should be able to re-use a lot of the code from the code you used when measuring the impact of lower case and number normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7444,
     "status": "ok",
     "timestamp": 1600522801649,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "laXsH-MZjXsx",
    "outputId": "21c51c18-e3fe-4233-c55d-6d52ac3ea233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming produced a 46.94% reduction in vocabulary size from 20224 to 10731\n"
     ]
    }
   ],
   "source": [
    "sample_size=10000\n",
    "tokenised_sentences = sample_sentences(reuters.sents(),sample_size)\n",
    "normalised_sentences=[number_normalise(sentence) for sentence in tokenised_sentences]\n",
    "stemmed_sentences = [[st.stem(token) for token in sentence] for sentence in normalised_sentences]\n",
    "raw_vocab_size = vocabulary_size(tokenised_sentences)\n",
    "stemmed_vocab_size = vocabulary_size(stemmed_sentences)\n",
    "print(\"Stemming produced a {0:.2f}% reduction in vocabulary size from {1} to {2}\".format(\n",
    "    100*(raw_vocab_size - stemmed_vocab_size)/raw_vocab_size,raw_vocab_size,stemmed_vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZzA9Cl6ZjXsz"
   },
   "source": [
    "### Exercise 2.2\n",
    "* Try using the WordNetLemmatizer <code>nltk.stem.wordnet.WordNetLemmatizer</code> instead of the Porter Stemmer.\n",
    "* Using a large sample of the Reuters corpus, establish the extent to which the vocabulary size reduced by lemmatization?\n",
    "* As an extension, you could look at different sample sizes and/or different corpora and display the results in a table or graph (e.g., using <code>pandas</code> and/or <code>matplotlib</code>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NBLtSKiimwG9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/juliewe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7027,
     "status": "ok",
     "timestamp": 1600522888894,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "4_RtCin6jXsz",
    "outputId": "c38c945a-21dd-4fa3-ff8f-899248dc9eb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatizing produced a 11.44% reduction in vocabulary size from 20097 to 17797\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_size=10000\n",
    "lemm = WordNetLemmatizer()\n",
    "tokenised_sentences = sample_sentences(reuters.sents(),sample_size)\n",
    "normalised_sentences=[number_normalise(sentence) for sentence in tokenised_sentences]\n",
    "stemmed_sentences = [[lemm.lemmatize(token) for token in sentence] for sentence in normalised_sentences]\n",
    "raw_vocab_size = vocabulary_size(tokenised_sentences)\n",
    "stemmed_vocab_size = vocabulary_size(stemmed_sentences)\n",
    "print(\"Lemmatizing produced a {0:.2f}% reduction in vocabulary size from {1} to {2}\".format(\n",
    "    100*(raw_vocab_size - stemmed_vocab_size)/raw_vocab_size,raw_vocab_size,stemmed_vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kBwfUlC3jXs1"
   },
   "source": [
    "### Punctuation and stop-word removal\n",
    "A stopword is a word that occurs so often that it loses its usefulness in some tasks. We may get more meaningful information from our corpus analysis if we remove stopwords and punctuation.\n",
    "\n",
    "The code below takes a list of tokens and creates a new list, which contains only those strings which are alphabetic and non-stop-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 792,
     "status": "ok",
     "timestamp": 1600523000919,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "2suL2eJOmqvW",
    "outputId": "844444ba-fae1-4ad4-a4c0-b7eeb6a0675a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/juliewe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 617,
     "status": "ok",
     "timestamp": 1600523002733,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "mhTSVWNcjXs2",
    "outputId": "c7d20cdd-e713-4239-8aa2-215e82eee1e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'cat', ',', 'which', 'is', 'really', 'fat', ',', 'sat', 'on', 'the', 'mat']\n",
      "['cat', 'really', 'fat', 'sat', 'mat']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stop = stopwords.words('english')\n",
    "tokens=\"The cat , which is really fat , sat on the mat\".lower().split()\n",
    "filtered_tokens = [w for w in tokens if w.isalpha() and w not in stop]\n",
    "print(tokens)\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGATIwNmjXs5"
   },
   "source": [
    "**Note**: `isalpha` only returns `True` if the string is entirely composed of alphabet characters. If you want a function to return `True` even when a word contains digits, then you should use `isalnum`.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_XyRZmVnjXs5"
   },
   "source": [
    "### Exercise 3.1\n",
    "- In the empty cell below, write code that looks at a large sample of the Reuters corpus, establishing what proportion of tokens are stop-words.\n",
    "- As extension, you could establish the mean (and or the distribution of the) number of stop-words per sentence; or compare the numbers of stop-words in different corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 901,
     "status": "ok",
     "timestamp": 1600523176329,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "scuIYe_xjXs6",
    "outputId": "522e75e2-d2ed-418b-8d79-f2fb2d428232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopword removal produced a 76.07% reduction in number of tokens from 314009 to 75153\n"
     ]
    }
   ],
   "source": [
    "num_stopwords = 0\n",
    "num_tokens = 0\n",
    "for sentence in tokenised_sentences:\n",
    "    for token in sentence:\n",
    "        num_tokens += 1\n",
    "        if token in stop:\n",
    "            num_stopwords += 1\n",
    "############################################\n",
    "\n",
    "print(\"Stopword removal produced a {0:.2f}% reduction in number of tokens from {1} to {2}\".format(\n",
    "    100*(num_tokens - num_stopwords)/num_tokens,num_tokens,num_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sUUOjqB9nRSp"
   },
   "source": [
    "### Exercise 3.2\n",
    "Explain the difference between the number of tokens in a corpus and the size of the vocabulary of a corpus.  Would you expect stopword removal to have a greater effect on the size of the vocabulary or the number of tokens in the corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ba2ncBYZjXs9"
   },
   "source": [
    "#### My answer\n",
    "The number of tokens counts every occurrence of a token whereas the size of a vocabulary is looking at distinct types - if the same token occurs $n$ times in the corpus, it adds $n$ to the number of tokens in the corpus but only 1 to the size of the vocabulary.  There are a relatively small number of stopwords which occur many times throughout a corpus - therefore, removing stopwords will have a much larger impact on the number of tokens in the corpus than on the vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLE2020_lab_2_2_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
