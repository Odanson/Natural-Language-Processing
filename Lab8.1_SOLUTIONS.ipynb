{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNr7m4n3Fvu7"
      },
      "source": [
        "# Lab Week 8: Part-of-Speech Tagging \n",
        "\n",
        "This week we are learning about part-of-speech (POS) tagging.  This involves deciding the correct part-of speech tag (e.g., noun, verb, adjective etc) for each word in a sentence.  Since the correct tag for each word depends not only on the current word but on the tags of those words around it, it is generally viewed as a **sequence labelling** problem.  In other words, for a given sequence of words, we are asking what is the most likely sequence of tags?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avA_7Rf2Fvu9",
        "outputId": "99c99540-b0f3-490a-9df7-8f1995486237"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/juliewe/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/juliewe/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "###mount google drive\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import sys\n",
        "import operator\n",
        "#make sure you append the path where your utils.py file is.\n",
        "sys.path.append('/content/drive/My Drive/NLE Notebooks/Week4LabsSolutions/')\n",
        "sys.path.append('/Users/juliewe/Documents/teaching/NLE/NLE2021/w4/Week4LabsSolutions/')\n",
        "from utils import *\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyHtJ98mFvvD"
      },
      "source": [
        "## Average PoS tag ambiguity \n",
        "The Part-of-Speech (PoS) tag ambiguity of a word type is a measure of how varied the PoS tags are for that type.   Note that here, we talk about the ambiguity of a word type rather than a word token because any given token has a single tag but different occurrences of the same type may have different tags.  For example, some occurrences of the word *bank* have the tag *noun* whereas others have the tag *verb*\n",
        "\n",
        "Some types are always (or almost always) labelled with the same PoS tag, so exhibit no (or very little) ambiguity. It is easy to predict the correct PoS tag for such words. \n",
        "\n",
        "On the other hand, a type that is commonly labelled by a variety of different PoS tags exhibits a high level of ambiguity, and is more challenging to deal with.\n",
        "\n",
        "In this session, we are going to be considering two measures of a type's ambiguity. We will be using the Wall Street Journal corpus as it has been hand-annotated with part of speech tags.  A 10% sample of it is available via NLTK via the `treebank` corpus reader.   \n",
        "We will consider \n",
        "* a simple measure that just **counts** the number of different tags that label the type. \n",
        "* a more complex information-theoretic measure based on **entropy**.\n",
        "\n",
        "First, we can use the treebank's method `tagged_words()` to get a list of all tokens in the corpus tagged with their POS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJiyMCEOU1kL",
        "outputId": "414f0b82-ae92-4e36-d6c3-d453679cc15e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Pierre', 'NNP'),\n",
              " ('Vinken', 'NNP'),\n",
              " (',', ','),\n",
              " ('61', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('old', 'JJ'),\n",
              " (',', ','),\n",
              " ('will', 'MD'),\n",
              " ('join', 'VB'),\n",
              " ('the', 'DT')]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import treebank\n",
        "\n",
        "taggedWSJ=treebank.tagged_words()\n",
        "\n",
        "taggedWSJ[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzuV6RLWU1kL",
        "outputId": "1eb651e9-bb79-43f9-caad-cb7fe1a0adbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100676"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(taggedWSJ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeHgtOFrFvvT"
      },
      "source": [
        "### Exercise 1.1\n",
        "Write a function `find_tag_distributions(tokentaglist)` which finds the (frequency) distributions of tags for every word in the input.\n",
        "* input: a list of pairs (token,tag)\n",
        "* returns: a dictionary of dictionaries.  The key to the outermost dictionary should be the word and the key to each internal dictionary should be the tag.  The value associated with the tag in the internal dictionary should be its frequency of occurrence.\n",
        "\n",
        "Test your function on `taggedWSJ` and look at the tag distribution for the word `the`.   You should find that you get:\n",
        "\n",
        "`{DT: 4038, 'NNP':1, 'JJ':5, 'CD':1}`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIuDtQHOFvvU"
      },
      "outputs": [],
      "source": [
        "def find_tag_distributions(tokentaglist,num=-1):\n",
        "    tag_dists={}\n",
        "    for i,(token,tag) in enumerate(tokentaglist):\n",
        "        current=tag_dists.get(token,{})\n",
        "        current[tag]=current.get(tag,0)+1\n",
        "        tag_dists[token]=current\n",
        "        if num > 0 and i>num:\n",
        "            print(\"Max number exceeded\")\n",
        "            break\n",
        "    return tag_dists\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Gj0dZW1SXaY"
      },
      "outputs": [],
      "source": [
        "distsWSJ=find_tag_distributions(taggedWSJ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flhCEOXoLrEN",
        "outputId": "3dd737c3-2af5-457a-cc6f-7ff43e280435"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'DT': 4038, 'NNP': 1, 'JJ': 5, 'CD': 1}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "distsWSJ['the']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfNPiMo9M9T3",
        "outputId": "f9c5fa07-c44c-44c7-9e40-84254590aa36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'NN': 1, 'JJ': 2}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "distsWSJ['white']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuJxTum4Fvve",
        "outputId": "0a5e07e7-c4a5-41ed-b721-c835a3ed0a12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'VBP': 4, 'NN': 7, 'VB': 2}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "distsWSJ['show']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QArRz4NYFvvy"
      },
      "source": [
        "### Exercise 1.2\n",
        "Write a function `simple_pos_ambiguity` which can take the tagged WSJ text and returns a dictionary containing the number of part of speech tags which each word type has.  Note that this is simply the length of the dictionary associated with that word in the output from `find_tag_distributions`.\n",
        "\n",
        "Check that you get the following results:\n",
        "the: 4\n",
        "white: 2\n",
        "show: 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wj-OMMgFvvz",
        "outputId": "01d22bea-9ffa-4e7f-a3d5-14afea2ce746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the: 4\n",
            "white: 2\n",
            "show: 3\n"
          ]
        }
      ],
      "source": [
        "def simple_pos_ambiguity(tag_dists):\n",
        "    return {word:len(tag_dist.keys()) for word,tag_dist in tag_dists.items()}\n",
        "\n",
        "#wsjreader=WSJCorpusReader()\n",
        "#taggedWSJ=wsjreader.tagged_words()\n",
        "ambiguity=simple_pos_ambiguity(distsWSJ)\n",
        "words=['the','white','show']\n",
        "for word in words:\n",
        "    print(\"{}: {}\".format(word,ambiguity[word]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSUNSo13Fvv2"
      },
      "source": [
        "### Exercise 1.3\n",
        "Find the mean average value of the `simple_pos_ambiguity` score for word types in the WSJ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kdfVMgBFvv2",
        "outputId": "429ea161-69bd-4dfb-ffde-15760afc539c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1106544165054804\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.mean(list(ambiguity.values())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTF6vp5VU1kP",
        "outputId": "67803308-2eb9-467c-8663-0637cd9f754b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_values"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(ambiguity.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em4JvkMTFvv5"
      },
      "source": [
        "## Entropy as a Measure of Tag Ambiguity\n",
        "\n",
        "**Entropy** is a measure of uncertainty. A word will have high entropy when it occurs the same number of times with each part of speech. There is maximum uncertainty as to which part of speech it has.\n",
        "\n",
        "The larger the part of speech tagset, the greater the potential for uncertainty, and the higher the entropy can be.\n",
        "\n",
        "In the cell below we see a function `entropy`. It's argument is a list of counts (which in our case are counts of how many times a word appeared with a given part of speech).\n",
        "\n",
        "Check that you understand how the code implements this definition of entropy:\n",
        "$$H([x_1,\\ldots,x_n])= - \\sum_{i=1}^nP(x_i)\\log_2 P(x_i)$$\n",
        "where $n$ is the number of PoS tags, and $x_i$ is a count of how many times the word was labelled with the $i$th PoS tag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fl2bLOJjFvv5"
      },
      "outputs": [],
      "source": [
        "def entropy(counts):            # counts = list of counts of occurrences of tags\n",
        "    total = sum(counts)         # get total number of occurrences\n",
        "    if not total: return 0      # if zero occurrences in total, then 0 entropy\n",
        "    entropy = 0\n",
        "    for i in counts:            # for each tag count\n",
        "        p = i/total      # probability that the token occurs with this tag\n",
        "        try:\n",
        "            entropy += p * math.log(p,2) # add to entropy\n",
        "        except ValueError: pass     # if p==0, then ignore this p\n",
        "    return -entropy if entropy else entropy   # only negate if nonzero, otherwise \n",
        "                                              # floats can return -0.0, which is weird.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZUPeuVuFvv9"
      },
      "source": [
        "### Exercise 2.1\n",
        "Experiment with the `entropy` function.\n",
        "- It takes a list of counts as its argument.\n",
        "- Compare the entropy of a list where all counts are the same with the entropy of a list of different counts.\n",
        "- Investigate the effect of varying the length of the list of counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4Lb79_qFvv9",
        "outputId": "6164910c-fed8-4b28-88b0-f7f1b44ca4a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.584962500721156"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "entropy([10,10,10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wphAKFu9U1kQ",
        "outputId": "7581f119-add1-474d-ed4b-a2ab85796678"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8166890883150209"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "entropy([10,1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keKtOqP3U1kR",
        "outputId": "2755938c-f555-4818-c85b-50239a61ec50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.584962500721156"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "entropy([100,100,100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afyavv6iU1kR",
        "outputId": "4a0f451c-aa2a-4f6e-aa88-a93dc71fc4cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.8073549220576046"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "entropy([10,10,10,10,10,10,10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xatJmrvU5WH",
        "outputId": "6a055561-d217-4f3a-b7df-97e2fd2d7668"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.005889922399433209"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "entropy([100000,10,10,10,10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgjNBjOvFvwA"
      },
      "source": [
        "### Exercise 2.2\n",
        "Write a function `entropy_ambiguity` which takes the tagged WSJ text and returns a dictionary containing the entropy of each word.\n",
        "\n",
        "Test it out your function; you should find:\n",
        "\n",
        "`white: 0.91829\n",
        "show: 1.41955\n",
        "the: 0.02036`\n",
        "\n",
        "How does this correspond to our intuitions about which word types are more difficult to correctly POS tag?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv7DgTJmFvwB",
        "outputId": "4a6d1760-e75a-47ca-a7e7-e4e085a92ac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "white: 0.9182958340544896\n",
            "show: 1.419556298571613\n",
            "the: 0.020359443628112334\n"
          ]
        }
      ],
      "source": [
        "def entropy_ambiguity(tag_dists):\n",
        "    #tag_dists=find_tag_distributions(tokentaglist)\n",
        "    ent_ambiguity={key:entropy(dist.values()) for key,dist in tag_dists.items()}\n",
        "    return ent_ambiguity\n",
        "\n",
        "#wsjreader=WSJCorpusReader()\n",
        "#taggedWSJ=wsjreader.tagged_words()\n",
        "entropydict=entropy_ambiguity(distsWSJ)\n",
        "words=['white','show','the']\n",
        "for word in words:\n",
        "    print(\"{}: {}\".format(word,entropydict.get(word,0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdE0Tk3dFvwE"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVla9DKcFvwF"
      },
      "source": [
        "## A Simple Unigram Tagger\n",
        "Now, we will be looking at part of speech tagging itself i.e., the problem of determining the correct tag for a given word token. We will\n",
        "\n",
        "* implement a unigram tagger\n",
        "* experiment with an off-the-shelf POS tagger which utilises information about the previous words or tags in the sequence.\n",
        "\n",
        "First, lets get some tagged text from the WSJ and split it into a training and a testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7QD05jqFvwF"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_train_test_pos(split=0.7):\n",
        "\n",
        "    taggedWSJ=treebank.tagged_words()\n",
        "    #we don't want to randomly select data because we need to preserve sequence information\n",
        "    #so we are just going to take the first part as training and the second as test\n",
        "    n=int(len(taggedWSJ)*split)\n",
        "    return taggedWSJ[:n],taggedWSJ[n:]\n",
        "\n",
        "train, test = get_train_test_pos(split=0.8)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycHhfUHwXGLq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk1z9qGbFvwI"
      },
      "source": [
        "Now, we build a unigram model of the tag distribution for each word type.  We use the `find_tag_distributions` function defined earlier and store the result in the variable `unigram_model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHPFWWjBFvwJ"
      },
      "outputs": [],
      "source": [
        "unigram_model=find_tag_distributions(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTJHn-YZXeTr",
        "outputId": "97d1eecf-4d33-4728-b239-f4fcaca831a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'DT': 3265, 'NNP': 1, 'JJ': 5, 'CD': 1}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unigram_model.get('the',{})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVrnzCnTFvwM"
      },
      "source": [
        "### Exercise 3.1\n",
        "Write a `uni_pos_tag` function which takes:\n",
        "* a sequence of tokens \\[wordtoken1,wordtoken2, ....\\]\n",
        "* a unigram model (stored as a dictionary of dictionaries\n",
        "and returns:\n",
        "* a tagged sequence of tokens \\[(wordtoken1,tag1),(wordtoken2,tag2),....\\]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SIfLgGUFvwN"
      },
      "outputs": [],
      "source": [
        "def best_tag(word,unimodel):\n",
        "    dist=unimodel.get(word,{})\n",
        "    ordered=sorted(list(dist.items()),key=operator.itemgetter(1),reverse=True)\n",
        "    return ordered[0][0]\n",
        "def uni_pos_tag(words,unimodel):\n",
        "    return [(word,best_tag(word,unimodel)) for word in words]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWTmaDgmU1kT",
        "outputId": "71327c49-376d-4e06-8f1a-fe9f302b0bd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'NN'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_tag(\"show\",unigram_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6qzxKZ4FvwQ"
      },
      "source": [
        "### Exercise 3.2\n",
        "Test that your function works on both the training data `train` and the testing data `test`.  Remember, you can separate the tokens and the tags into two separate lists using:\n",
        "* `train_toks,train_tags=zip(*train)`\n",
        "* `test_toks,test_tags=zip(*test)`\n",
        "\n",
        "Don't worry about evaluating the accuracy at this point (that's the next exercise) - just check that you can generate sequences of (token,tag) pairs in both cases.  What happens if there is a word in the test data that didn't occur in the training data?  You might need to update your `uni_pos_tag` function to take this into account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9D6cNoDFvwQ",
        "outputId": "d4f38715-c72f-40f0-e807-193e1fc88d31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Pierre', 'NNP'),\n",
              " ('Vinken', 'NNP'),\n",
              " (',', ','),\n",
              " ('61', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('old', 'JJ'),\n",
              " (',', ','),\n",
              " ('will', 'MD'),\n",
              " ('join', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('board', 'NN'),\n",
              " ('as', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('nonexecutive', 'JJ'),\n",
              " ('director', 'NN'),\n",
              " ('Nov.', 'NNP'),\n",
              " ('29', 'CD'),\n",
              " ('.', '.'),\n",
              " ('Mr.', 'NNP'),\n",
              " ('Vinken', 'NNP'),\n",
              " ('is', 'VBZ'),\n",
              " ('chairman', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('Elsevier', 'NNP'),\n",
              " ('N.V.', 'NNP'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " ('Dutch', 'JJ'),\n",
              " ('publishing', 'NN'),\n",
              " ('group', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Rudolph', 'NNP'),\n",
              " ('Agnew', 'NNP'),\n",
              " (',', ','),\n",
              " ('55', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('old', 'JJ'),\n",
              " ('and', 'CC'),\n",
              " ('former', 'JJ'),\n",
              " ('chairman', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('Consolidated', 'NNP'),\n",
              " ('Gold', 'NNP'),\n",
              " ('Fields', 'NNP'),\n",
              " ('PLC', 'NNP'),\n",
              " (',', ','),\n",
              " ('was', 'VBD'),\n",
              " ('named', 'VBN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('a', 'DT'),\n",
              " ('nonexecutive', 'JJ'),\n",
              " ('director', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('this', 'DT'),\n",
              " ('British', 'JJ'),\n",
              " ('industrial', 'JJ'),\n",
              " ('conglomerate', 'NN'),\n",
              " ('.', '.'),\n",
              " ('A', 'DT'),\n",
              " ('form', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('asbestos', 'NN'),\n",
              " ('once', 'RB'),\n",
              " ('used', 'VBN'),\n",
              " ('*', '-NONE-'),\n",
              " ('*', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('make', 'VB'),\n",
              " ('Kent', 'NNP'),\n",
              " ('cigarette', 'NN'),\n",
              " ('filters', 'NNS'),\n",
              " ('has', 'VBZ'),\n",
              " ('caused', 'VBN'),\n",
              " ('a', 'DT'),\n",
              " ('high', 'JJ'),\n",
              " ('percentage', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('cancer', 'NN'),\n",
              " ('deaths', 'NNS'),\n",
              " ('among', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('group', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('workers', 'NNS'),\n",
              " ('exposed', 'VBN'),\n",
              " ('*', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('it', 'PRP'),\n",
              " ('more', 'JJR'),\n",
              " ('than', 'IN'),\n",
              " ('30', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('ago', 'RB'),\n",
              " (',', ','),\n",
              " ('researchers', 'NNS'),\n",
              " ('reported', 'VBD'),\n",
              " ('0', '-NONE-'),\n",
              " ('*T*-1', '-NONE-'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('asbestos', 'NN'),\n",
              " ('fiber', 'NN'),\n",
              " (',', ','),\n",
              " ('crocidolite', 'NN'),\n",
              " (',', ','),\n",
              " ('is', 'VBZ'),\n",
              " ('unusually', 'RB'),\n",
              " ('resilient', 'JJ'),\n",
              " ('once', 'RB'),\n",
              " ('it', 'PRP'),\n",
              " ('enters', 'VBZ'),\n",
              " ('the', 'DT'),\n",
              " ('lungs', 'NNS'),\n",
              " (',', ','),\n",
              " ('with', 'IN'),\n",
              " ('even', 'RB'),\n",
              " ('brief', 'JJ'),\n",
              " ('exposures', 'NNS'),\n",
              " ('to', 'TO'),\n",
              " ('it', 'PRP'),\n",
              " ('causing', 'VBG'),\n",
              " ('symptoms', 'NNS'),\n",
              " ('that', 'IN'),\n",
              " ('*T*-1', '-NONE-'),\n",
              " ('show', 'NN'),\n",
              " ('up', 'RP'),\n",
              " ('decades', 'NNS'),\n",
              " ('later', 'JJ'),\n",
              " (',', ','),\n",
              " ('researchers', 'NNS'),\n",
              " ('said', 'VBD'),\n",
              " ('0', '-NONE-'),\n",
              " ('*T*-2', '-NONE-'),\n",
              " ('.', '.'),\n",
              " ('Lorillard', 'NNP'),\n",
              " ('Inc.', 'NNP'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " ('unit', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('New', 'NNP'),\n",
              " ('York-based', 'JJ'),\n",
              " ('Loews', 'NNP'),\n",
              " ('Corp.', 'NNP'),\n",
              " ('that', 'IN'),\n",
              " ('*T*-2', '-NONE-'),\n",
              " ('makes', 'VBZ'),\n",
              " ('Kent', 'NNP'),\n",
              " ('cigarettes', 'NNS'),\n",
              " (',', ','),\n",
              " ('stopped', 'VBD'),\n",
              " ('using', 'VBG'),\n",
              " ('crocidolite', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('its', 'PRP$'),\n",
              " ('Micronite', 'NN'),\n",
              " ('cigarette', 'NN'),\n",
              " ('filters', 'NNS'),\n",
              " ('in', 'IN'),\n",
              " ('1956', 'CD'),\n",
              " ('.', '.'),\n",
              " ('Although', 'IN'),\n",
              " ('preliminary', 'JJ'),\n",
              " ('findings', 'NNS'),\n",
              " ('were', 'VBD'),\n",
              " ('reported', 'VBD'),\n",
              " ('*-2', '-NONE-'),\n",
              " ('more', 'JJR'),\n",
              " ('than', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('year', 'NN'),\n",
              " ('ago', 'RB'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " ('latest', 'JJS'),\n",
              " ('results', 'NNS'),\n",
              " ('appear', 'VBP'),\n",
              " ('in', 'IN'),\n",
              " ('today', 'NN'),\n",
              " (\"'s\", 'POS'),\n",
              " ('New', 'NNP'),\n",
              " ('England', 'NNP'),\n",
              " ('Journal', 'NNP'),\n",
              " ('of', 'IN'),\n",
              " ('Medicine', 'NNP'),\n",
              " (',', ','),\n",
              " ('a', 'DT'),\n",
              " ('forum', 'NN'),\n",
              " ('likely', 'JJ'),\n",
              " ('*', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('bring', 'VB'),\n",
              " ('new', 'JJ'),\n",
              " ('attention', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('the', 'DT'),\n",
              " ('problem', 'NN'),\n",
              " ('.', '.'),\n",
              " ('A', 'DT'),\n",
              " ('Lorillard', 'NNP'),\n",
              " ('spokewoman', 'NN'),\n",
              " ('said', 'VBD'),\n",
              " (',', ','),\n",
              " ('``', '``'),\n",
              " ('This', 'DT'),\n",
              " ('is', 'VBZ'),\n",
              " ('an', 'DT'),\n",
              " ('old', 'JJ'),\n",
              " ('story', 'NN'),\n",
              " ('.', '.'),\n",
              " ('We', 'PRP'),\n",
              " (\"'re\", 'VBP'),\n",
              " ('talking', 'VBG'),\n",
              " ('about', 'IN'),\n",
              " ('years', 'NNS'),\n",
              " ('ago', 'RB'),\n",
              " ('before', 'IN'),\n",
              " ('anyone', 'NN'),\n",
              " ('heard', 'VBN'),\n",
              " ('of', 'IN'),\n",
              " ('asbestos', 'NN'),\n",
              " ('having', 'VBG'),\n",
              " ('any', 'DT'),\n",
              " ('questionable', 'JJ'),\n",
              " ('properties', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('There', 'EX'),\n",
              " ('is', 'VBZ'),\n",
              " ('no', 'DT'),\n",
              " ('asbestos', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('our', 'PRP$'),\n",
              " ('products', 'NNS'),\n",
              " ('now', 'RB'),\n",
              " ('.', '.'),\n",
              " (\"''\", \"''\"),\n",
              " ('Neither', 'DT'),\n",
              " ('Lorillard', 'NNP'),\n",
              " ('nor', 'CC'),\n",
              " ('the', 'DT'),\n",
              " ('researchers', 'NNS'),\n",
              " ('who', 'WP'),\n",
              " ('*T*-3', '-NONE-'),\n",
              " ('studied', 'VBN'),\n",
              " ('the', 'DT'),\n",
              " ('workers', 'NNS'),\n",
              " ('were', 'VBD'),\n",
              " ('aware', 'JJ'),\n",
              " ('of', 'IN'),\n",
              " ('any', 'DT'),\n",
              " ('research', 'NN'),\n",
              " ('on', 'IN'),\n",
              " ('smokers', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('Kent', 'NNP'),\n",
              " ('cigarettes', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('We', 'PRP'),\n",
              " ('have', 'VBP'),\n",
              " ('no', 'DT'),\n",
              " ('useful', 'JJ'),\n",
              " ('information', 'NN'),\n",
              " ('on', 'IN'),\n",
              " ('whether', 'IN'),\n",
              " ('users', 'NNS'),\n",
              " ('are', 'VBP'),\n",
              " ('at', 'IN'),\n",
              " ('risk', 'NN'),\n",
              " (',', ','),\n",
              " (\"''\", \"''\"),\n",
              " ('said', 'VBD'),\n",
              " ('*T*-1', '-NONE-'),\n",
              " ('James', 'NNP'),\n",
              " ('A.', 'NNP'),\n",
              " ('Talcott', 'NNP'),\n",
              " ('of', 'IN'),\n",
              " ('Boston', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('Dana-Farber', 'NNP'),\n",
              " ('Cancer', 'NNP'),\n",
              " ('Institute', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Dr.', 'NNP'),\n",
              " ('Talcott', 'NNP'),\n",
              " ('led', 'VBN'),\n",
              " ('a', 'DT'),\n",
              " ('team', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('researchers', 'NNS'),\n",
              " ('from', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('National', 'NNP'),\n",
              " ('Cancer', 'NNP'),\n",
              " ('Institute', 'NNP'),\n",
              " ('and', 'CC'),\n",
              " ('the', 'DT'),\n",
              " ('medical', 'JJ'),\n",
              " ('schools', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('Harvard', 'NNP'),\n",
              " ('University', 'NNP'),\n",
              " ('and', 'CC'),\n",
              " ('Boston', 'NNP'),\n",
              " ('University', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('Lorillard', 'NNP'),\n",
              " ('spokeswoman', 'NN'),\n",
              " ('said', 'VBD'),\n",
              " ('0', '-NONE-'),\n",
              " ('asbestos', 'NN'),\n",
              " ('was', 'VBD'),\n",
              " ('used', 'VBN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('in', 'IN'),\n",
              " ('``', '``'),\n",
              " ('very', 'RB'),\n",
              " ('modest', 'JJ'),\n",
              " ('amounts', 'NNS'),\n",
              " (\"''\", \"''\"),\n",
              " ('in', 'IN'),\n",
              " ('*', '-NONE-'),\n",
              " ('making', 'VBG'),\n",
              " ('paper', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('filters', 'NNS'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('early', 'JJ'),\n",
              " ('1950s', 'CD'),\n",
              " ('and', 'CC'),\n",
              " ('replaced', 'VBN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('with', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('different', 'JJ'),\n",
              " ('type', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('filter', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('1956', 'CD'),\n",
              " ('.', '.'),\n",
              " ('From', 'IN'),\n",
              " ('1953', 'CD'),\n",
              " ('to', 'TO'),\n",
              " ('1955', 'CD'),\n",
              " (',', ','),\n",
              " ('9.8', 'CD'),\n",
              " ('billion', 'CD'),\n",
              " ('Kent', 'NNP'),\n",
              " ('cigarettes', 'NNS'),\n",
              " ('with', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('filters', 'NNS'),\n",
              " ('were', 'VBD'),\n",
              " ('sold', 'VBN'),\n",
              " ('*-3', '-NONE-'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " ('company', 'NN'),\n",
              " ('said', 'VBD'),\n",
              " ('0', '-NONE-'),\n",
              " ('*T*-1', '-NONE-'),\n",
              " ('.', '.'),\n",
              " ('Among', 'IN'),\n",
              " ('33', 'CD'),\n",
              " ('men', 'NNS'),\n",
              " ('who', 'WP'),\n",
              " ('*T*-4', '-NONE-'),\n",
              " ('worked', 'VBD'),\n",
              " ('closely', 'RB'),\n",
              " ('with', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('substance', 'NN'),\n",
              " (',', ','),\n",
              " ('28', 'CD'),\n",
              " ('*ICH*-1', '-NONE-'),\n",
              " ('have', 'VBP'),\n",
              " ('died', 'VBN'),\n",
              " ('--', ':'),\n",
              " ('more', 'JJR'),\n",
              " ('than', 'IN'),\n",
              " ('three', 'CD'),\n",
              " ('times', 'NNS'),\n",
              " ('the', 'DT'),\n",
              " ('expected', 'VBN'),\n",
              " ('number', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Four', 'CD'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('five', 'CD'),\n",
              " ('surviving', 'VBG'),\n",
              " ('workers', 'NNS'),\n",
              " ('have', 'VBP'),\n",
              " ('asbestos-related', 'JJ'),\n",
              " ('diseases', 'NNS'),\n",
              " (',', ','),\n",
              " ('including', 'VBG'),\n",
              " ('three', 'CD'),\n",
              " ('with', 'IN'),\n",
              " ('recently', 'RB'),\n",
              " ('diagnosed', 'VBN'),\n",
              " ('cancer', 'NN'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('total', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('18', 'CD'),\n",
              " ('deaths', 'NNS'),\n",
              " ('from', 'IN'),\n",
              " ('malignant', 'JJ'),\n",
              " ('mesothelioma', 'NN'),\n",
              " (',', ','),\n",
              " ('lung', 'NN'),\n",
              " ('cancer', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('asbestosis', 'NN'),\n",
              " ('was', 'VBD'),\n",
              " ('far', 'RB'),\n",
              " ('higher', 'JJR'),\n",
              " ('than', 'IN'),\n",
              " ('*', '-NONE-'),\n",
              " ('expected', 'VBN'),\n",
              " ('*?*', '-NONE-'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " ('researchers', 'NNS'),\n",
              " ('said', 'VBD'),\n",
              " ('0', '-NONE-'),\n",
              " ('*T*-1', '-NONE-'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('The', 'DT'),\n",
              " ('morbidity', 'NN'),\n",
              " ('rate', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('striking', 'JJ'),\n",
              " ('finding', 'NN'),\n",
              " ('among', 'IN'),\n",
              " ('those', 'DT'),\n",
              " ('of', 'IN'),\n",
              " ('us', 'PRP'),\n",
              " ('who', 'WP'),\n",
              " ('*T*-5', '-NONE-'),\n",
              " ('study', 'NN'),\n",
              " ('asbestos-related', 'JJ'),\n",
              " ('diseases', 'NNS'),\n",
              " (',', ','),\n",
              " (\"''\", \"''\"),\n",
              " ('said', 'VBD'),\n",
              " ('*T*-1', '-NONE-'),\n",
              " ('Dr.', 'NNP'),\n",
              " ('Talcott', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('percentage', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('lung', 'NN'),\n",
              " ('cancer', 'NN'),\n",
              " ('deaths', 'NNS'),\n",
              " ('among', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('workers', 'NNS'),\n",
              " ('at', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('West', 'NNP'),\n",
              " ('Groton', 'NNP'),\n",
              " (',', ','),\n",
              " ('Mass.', 'NNP'),\n",
              " (',', ','),\n",
              " ('paper', 'NN'),\n",
              " ('factory', 'NN'),\n",
              " ('appears', 'VBZ'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('be', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('highest', 'JJS'),\n",
              " ('for', 'IN'),\n",
              " ('any', 'DT'),\n",
              " ('asbestos', 'NN'),\n",
              " ('workers', 'NNS'),\n",
              " ('studied', 'VBN'),\n",
              " ('*', '-NONE-'),\n",
              " ('in', 'IN'),\n",
              " ('Western', 'NNP'),\n",
              " ('industrialized', 'VBN'),\n",
              " ('countries', 'NNS'),\n",
              " (',', ','),\n",
              " ('he', 'PRP'),\n",
              " ('said', 'VBD'),\n",
              " ('0', '-NONE-'),\n",
              " ('*T*-2', '-NONE-'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('plant', 'NN'),\n",
              " (',', ','),\n",
              " ('which', 'WDT'),\n",
              " ('*T*-1', '-NONE-'),\n",
              " ('is', 'VBZ'),\n",
              " ('owned', 'VBN'),\n",
              " ('*-4', '-NONE-'),\n",
              " ('by', 'IN'),\n",
              " ('Hollingsworth', 'NNP'),\n",
              " ('&', 'CC'),\n",
              " ('Vose', 'NNP'),\n",
              " ('Co.', 'NNP'),\n",
              " (',', ','),\n",
              " ('was', 'VBD'),\n",
              " ('under', 'IN'),\n",
              " ('contract', 'NN'),\n",
              " ('*ICH*-2', '-NONE-'),\n",
              " ('with', 'IN'),\n",
              " ('Lorillard', 'NNP'),\n",
              " ('*', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('make', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('cigarette', 'NN'),\n",
              " ('filters', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('finding', 'NN'),\n",
              " ('probably', 'RB'),\n",
              " ('will', 'MD'),\n",
              " ('support', 'VB'),\n",
              " ('those', 'DT'),\n",
              " ('who', 'WP'),\n",
              " ('*T*-6', '-NONE-'),\n",
              " ('argue', 'VBP'),\n",
              " ('that', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('U.S.', 'NNP'),\n",
              " ('should', 'MD'),\n",
              " ('regulate', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('class', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('asbestos', 'NN'),\n",
              " ('including', 'VBG'),\n",
              " ('crocidolite', 'NN'),\n",
              " ('more', 'JJR'),\n",
              " ('stringently', 'RB'),\n",
              " ('than', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('common', 'JJ'),\n",
              " ('kind', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('asbestos', 'NN'),\n",
              " (',', ','),\n",
              " ('chrysotile', 'NN'),\n",
              " (',', ','),\n",
              " ('found', 'VBD'),\n",
              " ('*', '-NONE-'),\n",
              " ('in', 'IN'),\n",
              " ('most', 'JJS'),\n",
              " ('schools', 'NNS'),\n",
              " ('and', 'CC'),\n",
              " ('other', 'JJ'),\n",
              " ('buildings', 'NNS'),\n",
              " (',', ','),\n",
              " ('Dr.', 'NNP'),\n",
              " ('Talcott', 'NNP'),\n",
              " ('said', 'VBD'),\n",
              " ('0', '-NONE-'),\n",
              " ('*T*-1', '-NONE-'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('U.S.', 'NNP'),\n",
              " ('is', 'VBZ'),\n",
              " ('one', 'CD'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('few', 'JJ'),\n",
              " ('industrialized', 'VBN'),\n",
              " ('nations', 'NNS'),\n",
              " ('that', 'IN'),\n",
              " ('*T*-7', '-NONE-'),\n",
              " ('does', 'VBZ'),\n",
              " (\"n't\", 'RB'),\n",
              " ('have', 'VBP'),\n",
              " ('a', 'DT'),\n",
              " ('higher', 'JJR'),\n",
              " ('standard', 'JJ'),\n",
              " ('of', 'IN'),\n",
              " ('regulation', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('smooth', 'JJ'),\n",
              " (',', ','),\n",
              " ('needle-like', 'JJ'),\n",
              " ('fibers', 'NNS'),\n",
              " ('such', 'JJ'),\n",
              " ('as', 'IN'),\n",
              " ('crocidolite', 'NN'),\n",
              " ('that', 'IN'),\n",
              " ('*T*-1', '-NONE-'),\n",
              " ('are', 'VBP'),\n",
              " ('classified', 'VBN'),\n",
              " ('*-5', '-NONE-'),\n",
              " ('as', 'IN'),\n",
              " ('amphobiles', 'NNS'),\n",
              " (',', ','),\n",
              " ('according', 'VBG'),\n",
              " ('to', 'TO'),\n",
              " ('Brooke', 'NNP'),\n",
              " ('T.', 'NNP'),\n",
              " ('Mossman', 'NNP'),\n",
              " (',', ','),\n",
              " ('a', 'DT'),\n",
              " ('professor', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('pathlogy', 'NN'),\n",
              " ('at', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('University', 'NNP'),\n",
              " ('of', 'IN'),\n",
              " ('Vermont', 'NNP'),\n",
              " ('College', 'NNP'),\n",
              " ('of', 'IN'),\n",
              " ('Medicine', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('More', 'JJR'),\n",
              " ('common', 'JJ'),\n",
              " ('chrysotile', 'NN'),\n",
              " ('fibers', 'NNS'),\n",
              " ('are', 'VBP'),\n",
              " ('curly', 'JJ'),\n",
              " ('and', 'CC'),\n",
              " ('are', 'VBP'),\n",
              " ('more', 'JJR'),\n",
              " ('easily', 'RB'),\n",
              " ('rejected', 'VBD'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('by', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('body', 'NN'),\n",
              " (',', ','),\n",
              " ('Dr.', 'NNP'),\n",
              " ('Mossman', 'NNP'),\n",
              " ('explained', 'VBD'),\n",
              " ('0', '-NONE-'),\n",
              " ('*T*-2', '-NONE-'),\n",
              " ('.', '.'),\n",
              " ('In', 'IN'),\n",
              " ('July', 'NNP'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " ('Environmental', 'NNP'),\n",
              " ('Protection', 'NNP'),\n",
              " ('Agency', 'NNP'),\n",
              " ('imposed', 'VBD'),\n",
              " ('a', 'DT'),\n",
              " ('gradual', 'JJ'),\n",
              " ('ban', 'NN'),\n",
              " ('on', 'IN'),\n",
              " ('virtually', 'RB'),\n",
              " ('all', 'DT'),\n",
              " ('uses', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('asbestos', 'NN'),\n",
              " ('.', '.'),\n",
              " ('By', 'IN'),\n",
              " ('1997', 'CD'),\n",
              " (',', ','),\n",
              " ('almost', 'RB'),\n",
              " ('all', 'DT'),\n",
              " ('remaining', 'VBG'),\n",
              " ('uses', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('cancer-causing', 'JJ'),\n",
              " ('asbestos', 'NN'),\n",
              " ('will', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('outlawed', 'VBN'),\n",
              " ('*-6', '-NONE-'),\n",
              " ('.', '.'),\n",
              " ('About', 'IN'),\n",
              " ('160', 'CD'),\n",
              " ('workers', 'NNS'),\n",
              " ('at', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('factory', 'NN'),\n",
              " ('that', 'IN'),\n",
              " ('*T*-8', '-NONE-'),\n",
              " ('made', 'VBN'),\n",
              " ('paper', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('Kent', 'NNP'),\n",
              " ('filters', 'NNS'),\n",
              " ('were', 'VBD'),\n",
              " ('exposed', 'VBN'),\n",
              " ('*-7', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('asbestos', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('1950s', 'CD'),\n",
              " ('.', '.'),\n",
              " ('Areas', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('factory', 'NN'),\n",
              " ('*ICH*-2', '-NONE-'),\n",
              " ('were', 'VBD'),\n",
              " ('particularly', 'RB'),\n",
              " ('dusty', 'JJ'),\n",
              " ('where', 'WRB'),\n",
              " ('the', 'DT'),\n",
              " ('crocidolite', 'NN'),\n",
              " ('was', 'VBD'),\n",
              " ('used', 'VBN'),\n",
              " ('*-8', '-NONE-'),\n",
              " ('*T*-1', '-NONE-'),\n",
              " ('.', '.'),\n",
              " ('Workers', 'NNS'),\n",
              " ('dumped', 'VBD'),\n",
              " ('large', 'JJ'),\n",
              " ('burlap', 'NN'),\n",
              " ('sacks', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('imported', 'VBN'),\n",
              " ('material', 'NN'),\n",
              " ('into', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('huge', 'JJ'),\n",
              " ('bin', 'NN'),\n",
              " (',', ','),\n",
              " ('poured', 'VBD'),\n",
              " ('in', 'IN'),\n",
              " ('cotton', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('acetate', 'NN'),\n",
              " ('fibers', 'NNS'),\n",
              " ('and', 'CC'),\n",
              " ('mechanically', 'RB'),\n",
              " ('mixed', 'VBN'),\n",
              " ('the', 'DT'),\n",
              " ('dry', 'JJ'),\n",
              " ('fibers', 'NNS'),\n",
              " ('in', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('process', 'NN'),\n",
              " ('used', 'VBN'),\n",
              " ('*', '-NONE-'),\n",
              " ('*', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('make', 'VB'),\n",
              " ('filters', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('Workers', 'NNS'),\n",
              " ('described', 'VBD'),\n",
              " ('``', '``'),\n",
              " ('clouds', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('blue', 'JJ'),\n",
              " ('dust', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " ('that', 'IN'),\n",
              " ('*T*-1', '-NONE-'),\n",
              " ('hung', 'VBD'),\n",
              " ('over', 'IN'),\n",
              " ('parts', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('factory', 'NN'),\n",
              " (',', ','),\n",
              " ('even', 'RB'),\n",
              " ('though', 'IN'),\n",
              " ('exhaust', 'NN'),\n",
              " ('fans', 'NNS'),\n",
              " ('ventilated', 'VBD'),\n",
              " ('the', 'DT'),\n",
              " ('area', 'NN'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('There', 'EX'),\n",
              " (\"'s\", 'POS'),\n",
              " ('no', 'DT'),\n",
              " ('question', 'NN'),\n",
              " ('that', 'IN'),\n",
              " ('some', 'DT'),\n",
              " ('of', 'IN'),\n",
              " ('those', 'DT'),\n",
              " ('workers', 'NNS'),\n",
              " ('and', 'CC'),\n",
              " ('managers', 'NNS'),\n",
              " ('contracted', 'VBD'),\n",
              " ('asbestos-related', 'JJ'),\n",
              " ('diseases', 'NNS'),\n",
              " (',', ','),\n",
              " (\"''\", \"''\"),\n",
              " ('said', 'VBD'),\n",
              " ('*T*-1', '-NONE-'),\n",
              " ('Darrell', 'NNP'),\n",
              " ('Phillips', 'NNP'),\n",
              " (',', ','),\n",
              " ('vice', 'NN'),\n",
              " ('president', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('human', 'JJ'),\n",
              " ('resources', 'NNS'),\n",
              " ('for', 'IN'),\n",
              " ('Hollingsworth', 'NNP'),\n",
              " ('&', 'CC'),\n",
              " ('Vose', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('But', 'CC'),\n",
              " ('you', 'PRP'),\n",
              " ('have', 'VBP'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('recognize', 'VB'),\n",
              " ('that', 'IN'),\n",
              " ('these', 'DT'),\n",
              " ('events', 'NNS'),\n",
              " ('took', 'VBD'),\n",
              " ('place', 'NN'),\n",
              " ('35', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('ago', 'RB'),\n",
              " ('.', '.'),\n",
              " ('It', 'PRP'),\n",
              " ('has', 'VBZ'),\n",
              " ('no', 'DT'),\n",
              " ('bearing', 'NN'),\n",
              " ('on', 'IN'),\n",
              " ('our', 'PRP$'),\n",
              " ('work', 'NN'),\n",
              " ('force', 'NN'),\n",
              " ('today', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Yields', 'NNS'),\n",
              " ('on', 'IN'),\n",
              " ('money-market', 'JJ'),\n",
              " ('mutual', 'JJ'),\n",
              " ('funds', 'NNS'),\n",
              " ('continued', 'VBD'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('slide', 'NN'),\n",
              " (',', ','),\n",
              " ('amid', 'IN'),\n",
              " ('signs', 'NNS'),\n",
              " ('that', 'IN'),\n",
              " ('portfolio', 'NN'),\n",
              " ('managers', 'NNS'),\n",
              " ('expect', 'VBP'),\n",
              " ('further', 'JJ'),\n",
              " ('declines', 'NNS'),\n",
              " ('in', 'IN'),\n",
              " ('interest', 'NN'),\n",
              " ('rates', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('average', 'JJ'),\n",
              " ('seven-day', 'JJ'),\n",
              " ('compound', 'NN'),\n",
              " ('yield', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('400', 'CD'),\n",
              " ('taxable', 'JJ'),\n",
              " ('funds', 'NNS'),\n",
              " ('tracked', 'VBN'),\n",
              " ('*', '-NONE-'),\n",
              " ('by', 'IN'),\n",
              " ('IBC', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('Money', 'NNP'),\n",
              " ('Fund', 'NNP'),\n",
              " ('Report', 'NNP'),\n",
              " ('eased', 'VBD'),\n",
              " ('a', 'DT'),\n",
              " ('fraction', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('percentage', 'NN'),\n",
              " ('point', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('8.45', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('from', 'IN'),\n",
              " ('8.47', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('week', 'NN'),\n",
              " ('ended', 'VBD'),\n",
              " ('Tuesday', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Compound', 'NN'),\n",
              " ('yields', 'NNS'),\n",
              " ('assume', 'VBP'),\n",
              " ('reinvestment', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('dividends', 'NNS'),\n",
              " ('and', 'CC'),\n",
              " ('that', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('current', 'JJ'),\n",
              " ('yield', 'NN'),\n",
              " ('continues', 'VBZ'),\n",
              " ('for', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('year', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Average', 'JJ'),\n",
              " ('maturity', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('funds', 'NNS'),\n",
              " (\"'\", 'POS'),\n",
              " ('investments', 'NNS'),\n",
              " ('lengthened', 'VBD'),\n",
              " ('by', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('day', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('41', 'CD'),\n",
              " ('days', 'NNS'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " ('longest', 'JJS'),\n",
              " ('since', 'IN'),\n",
              " ('early', 'JJ'),\n",
              " ('August', 'NNP'),\n",
              " (',', ','),\n",
              " ('according', 'VBG'),\n",
              " ('to', 'TO'),\n",
              " ('Donoghue', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('.', '.'),\n",
              " ('Longer', 'JJR'),\n",
              " ('maturities', 'NNS'),\n",
              " ('are', 'VBP'),\n",
              " ('thought', 'VBD'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('indicate', 'VB'),\n",
              " ('declining', 'VBG'),\n",
              " ('interest', 'NN'),\n",
              " ('rates', 'NNS'),\n",
              " ('because', 'IN'),\n",
              " ('they', 'PRP'),\n",
              " ('permit', 'VB'),\n",
              " ('portfolio', 'NN'),\n",
              " ('managers', 'NNS'),\n",
              " ('to', 'TO'),\n",
              " ('retain', 'VB'),\n",
              " ('relatively', 'RB'),\n",
              " ('higher', 'JJR'),\n",
              " ('rates', 'NNS'),\n",
              " ('for', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('longer', 'JJR'),\n",
              " ('period', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Shorter', 'JJR'),\n",
              " ('maturities', 'NNS'),\n",
              " ('are', 'VBP'),\n",
              " ('considered', 'VBN'),\n",
              " ('*-9', '-NONE-'),\n",
              " ('a', 'DT'),\n",
              " ('sign', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('rising', 'VBG'),\n",
              " ('rates', 'NNS'),\n",
              " ('because', 'IN'),\n",
              " ('portfolio', 'NN'),\n",
              " ('managers', 'NNS'),\n",
              " ('can', 'MD'),\n",
              " ('capture', 'VB'),\n",
              " ('higher', 'JJR'),\n",
              " ('rates', 'NNS'),\n",
              " ('sooner', 'RB'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('average', 'JJ'),\n",
              " ('maturity', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('funds', 'NNS'),\n",
              " ('open', 'JJ'),\n",
              " ('only', 'RB'),\n",
              " ('to', 'TO'),\n",
              " ('institutions', 'NNS'),\n",
              " (',', ','),\n",
              " ('considered', 'VBN'),\n",
              " ('by', 'IN'),\n",
              " ('some', 'DT'),\n",
              " ('*', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ...]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_toks,train_tags=zip(*train)\n",
        "uni_pos_tag(train_toks,unigram_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrP8xwGoU1kT",
        "outputId": "baeb2ee5-9301-4546-a66d-8a9b7d52dfcd"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-e1483510419f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_toks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_tags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muni_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_toks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munigram_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-fe0f22d2f908>\u001b[0m in \u001b[0;36muni_pos_tag\u001b[0;34m(words, unimodel)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muni_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munimodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munimodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-fe0f22d2f908>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muni_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munimodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munimodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-fe0f22d2f908>\u001b[0m in \u001b[0;36mbest_tag\u001b[0;34m(word, unimodel)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munimodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mordered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muni_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munimodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munimodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "test_toks,test_tags=zip(*test)\n",
        "uni_pos_tag(test_toks,unigram_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Vep-r8lFvwW",
        "outputId": "39a3038a-eabf-4bac-b6e3-0e996db7d83b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'NN'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def back_off(unimodel):\n",
        "    #find which is the most frequent tag assigned to any type\n",
        "    combined={}\n",
        "    for adict in unimodel.values():\n",
        "        for (tag,value) in adict.items():\n",
        "            combined[tag]=combined.get(tag,0)+value\n",
        "    ordered=sorted(list(combined.items()),key=operator.itemgetter(1),reverse=True)\n",
        "    return ordered[0][0]\n",
        "\n",
        "back_off(unigram_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xev9H6blFvwY"
      },
      "outputs": [],
      "source": [
        "def best_tag(word,unimodel,default='N'):\n",
        "    dist=unimodel.get(word,{default:1})\n",
        "    ordered=sorted(list(dist.items()),key=operator.itemgetter(1),reverse=True)\n",
        "    return ordered[0][0]\n",
        "def uni_pos_tag(words,unimodel):\n",
        "    default_tag=back_off(unimodel)\n",
        "    return [(word,best_tag(word,unimodel,default=default_tag)) for word in words]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tF6Y9JiRFvwc",
        "outputId": "2cb87628-a743-45ff-edbc-a66b2dbd6eca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('The', 'DT'),\n",
              " ('Treasury', 'NNP'),\n",
              " ('said', 'VBD'),\n",
              " ('0', '-NONE-'),\n",
              " ('the', 'DT'),\n",
              " ('refunding', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('contingent', 'NN'),\n",
              " ('upon', 'IN'),\n",
              " ('congressional', 'JJ'),\n",
              " ('and', 'CC'),\n",
              " ('presidential', 'JJ'),\n",
              " ('passage', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('an', 'DT'),\n",
              " ('increase', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('federal', 'JJ'),\n",
              " ('debt', 'NN'),\n",
              " ('ceiling', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Until', 'IN'),\n",
              " ('such', 'JJ'),\n",
              " ('action', 'NN'),\n",
              " ('takes', 'VBZ'),\n",
              " ('places', 'NNS'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " ('Treasury', 'NNP'),\n",
              " ('has', 'VBZ'),\n",
              " ('no', 'DT'),\n",
              " ('ability', 'NN'),\n",
              " ('*', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('issue', 'NN'),\n",
              " ('new', 'JJ'),\n",
              " ('debt', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('any', 'DT'),\n",
              " ('kind', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Meanwhile', 'RB'),\n",
              " (',', ','),\n",
              " ('Treasury', 'NNP'),\n",
              " ('bonds', 'NNS'),\n",
              " ('ended', 'VBD'),\n",
              " ('modestly', 'RB'),\n",
              " ('higher', 'JJR'),\n",
              " ('in', 'IN'),\n",
              " ('quiet', 'JJ'),\n",
              " ('trading', 'NN'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('benchmark', 'NN'),\n",
              " ('30-year', 'JJ'),\n",
              " ('bond', 'NN'),\n",
              " ('about', 'IN'),\n",
              " ('1\\\\/4', 'CD'),\n",
              " ('point', 'NN'),\n",
              " (',', ','),\n",
              " ('or', 'CC'),\n",
              " ('$', '$'),\n",
              " ('2.50', 'CD'),\n",
              " ('*U*', '-NONE-'),\n",
              " ('for', 'IN'),\n",
              " ('each', 'DT'),\n",
              " ('$', '$'),\n",
              " ('1,000', 'CD'),\n",
              " ('*U*', '-NONE-'),\n",
              " ('face', 'NN'),\n",
              " ('amount', 'NN'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('benchmark', 'NN'),\n",
              " ('was', 'VBD'),\n",
              " ('priced', 'VBN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('at', 'IN'),\n",
              " ('102', 'NN'),\n",
              " ('22\\\\/32', 'NN'),\n",
              " ('*-2', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('yield', 'NN'),\n",
              " ('7.88', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('compared', 'VBN'),\n",
              " ('with', 'IN'),\n",
              " ('102', 'NN'),\n",
              " ('12\\\\/32', 'NN'),\n",
              " ('*', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('yield', 'NN'),\n",
              " ('7.90', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('Tuesday', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('latest', 'JJS'),\n",
              " ('10-year', 'JJ'),\n",
              " ('notes', 'NNS'),\n",
              " ('were', 'VBD'),\n",
              " ('quoted', 'VBN'),\n",
              " ('at', 'IN'),\n",
              " ('100', 'CD'),\n",
              " ('22\\\\/32', 'NN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('yield', 'NN'),\n",
              " ('7.88', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('compared', 'VBN'),\n",
              " ('with', 'IN'),\n",
              " ('100', 'CD'),\n",
              " ('16\\\\/32', 'NN'),\n",
              " ('*', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('yield', 'NN'),\n",
              " ('7.90', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('discount', 'NN'),\n",
              " ('rate', 'NN'),\n",
              " ('on', 'IN'),\n",
              " ('three-month', 'NN'),\n",
              " ('Treasury', 'NNP'),\n",
              " ('bills', 'NNS'),\n",
              " ('was', 'VBD'),\n",
              " ('essentially', 'RB'),\n",
              " ('unchanged', 'JJ'),\n",
              " ('at', 'IN'),\n",
              " ('7.79', 'NN'),\n",
              " ('%', 'NN'),\n",
              " (',', ','),\n",
              " ('while', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('rate', 'NN'),\n",
              " ('on', 'IN'),\n",
              " ('six-month', 'JJ'),\n",
              " ('bills', 'NNS'),\n",
              " ('was', 'VBD'),\n",
              " ('slightly', 'RB'),\n",
              " ('lower', 'JJR'),\n",
              " ('at', 'IN'),\n",
              " ('7.52', 'NN'),\n",
              " ('%', 'NN'),\n",
              " ('compared', 'VBN'),\n",
              " ('with', 'IN'),\n",
              " ('7.60', 'NN'),\n",
              " ('%', 'NN'),\n",
              " ('Tuesday', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Corporate', 'NNP'),\n",
              " ('Issues', 'NN'),\n",
              " ('IBM', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('$', '$'),\n",
              " ('750', 'CD'),\n",
              " ('million', 'CD'),\n",
              " ('*U*', '-NONE-'),\n",
              " ('debenture', 'NN'),\n",
              " ('offering', 'NN'),\n",
              " ('dominated', 'VBN'),\n",
              " ('activity', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('corporate', 'JJ'),\n",
              " ('debt', 'NN'),\n",
              " ('market', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Meanwhile', 'RB'),\n",
              " (',', ','),\n",
              " ('most', 'JJS'),\n",
              " ('investment-grade', 'JJ'),\n",
              " ('bonds', 'NNS'),\n",
              " ('ended', 'VBD'),\n",
              " ('unchanged', 'JJ'),\n",
              " ('to', 'TO'),\n",
              " ('as', 'IN'),\n",
              " ('much', 'RB'),\n",
              " ('as', 'IN'),\n",
              " ('1\\\\/8', 'CD'),\n",
              " ('point', 'NN'),\n",
              " ('higher', 'JJR'),\n",
              " ('.', '.'),\n",
              " ('In', 'IN'),\n",
              " ('its', 'PRP$'),\n",
              " ('latest', 'JJS'),\n",
              " ('compilation', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('performance', 'NN'),\n",
              " ('statistics', 'NNS'),\n",
              " (',', ','),\n",
              " ('Moody', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('Investors', 'NNS'),\n",
              " ('Service', 'NNP'),\n",
              " ('found', 'VBD'),\n",
              " ('that', 'IN'),\n",
              " ('investment-grade', 'JJ'),\n",
              " ('bonds', 'NNS'),\n",
              " ('posted', 'VBD'),\n",
              " ('a', 'DT'),\n",
              " ('total', 'NN'),\n",
              " ('return', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('2.7', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('October', 'NNP'),\n",
              " ('while', 'IN'),\n",
              " ('junk', 'NN'),\n",
              " ('bonds', 'NNS'),\n",
              " ('showed', 'VBD'),\n",
              " ('a', 'DT'),\n",
              " ('negative', 'JJ'),\n",
              " ('return', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('1.5', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Moody', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('said', 'VBD'),\n",
              " ('0', '-NONE-'),\n",
              " ('those', 'DT'),\n",
              " ('returns', 'NNS'),\n",
              " ('compare', 'NN'),\n",
              " ('with', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('3.8', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('total', 'NN'),\n",
              " ('return', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('longer-term', 'JJ'),\n",
              " ('Treasury', 'NNP'),\n",
              " ('notes', 'NNS'),\n",
              " ('and', 'CC'),\n",
              " ('bonds', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('Total', 'JJ'),\n",
              " ('return', 'NN'),\n",
              " ('measures', 'NNS'),\n",
              " ('price', 'NN'),\n",
              " ('changes', 'NNS'),\n",
              " ('and', 'CC'),\n",
              " ('interest', 'NN'),\n",
              " ('income', 'NN'),\n",
              " ('.', '.'),\n",
              " ('For', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('year', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('date', 'NN'),\n",
              " (',', ','),\n",
              " ('Moody', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('said', 'VBD'),\n",
              " ('0', '-NONE-'),\n",
              " ('total', 'NN'),\n",
              " ('returns', 'NNS'),\n",
              " ('were', 'VBD'),\n",
              " ('topped', 'NN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('by', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('16.5', 'NN'),\n",
              " ('%', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('longer-term', 'JJ'),\n",
              " ('Treasury', 'NNP'),\n",
              " ('issues', 'NNS'),\n",
              " (',', ','),\n",
              " ('*-2', '-NONE-'),\n",
              " ('closely', 'RB'),\n",
              " ('followed', 'VBD'),\n",
              " ('*-3', '-NONE-'),\n",
              " ('by', 'IN'),\n",
              " ('15', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('investment-grade', 'JJ'),\n",
              " ('bonds', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('Junk', 'NN'),\n",
              " ('bonds', 'NNS'),\n",
              " ('trailed', 'VBD'),\n",
              " ('the', 'DT'),\n",
              " ('group', 'NN'),\n",
              " ('again', 'RB'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('Even', 'RB'),\n",
              " ('the', 'DT'),\n",
              " ('7.2', 'NN'),\n",
              " ('%', 'NN'),\n",
              " ('return', 'NN'),\n",
              " ('from', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('risk-free', 'NN'),\n",
              " ('three-month', 'NN'),\n",
              " ('Treasury', 'NNP'),\n",
              " ('bill', 'NN'),\n",
              " ('has', 'VBZ'),\n",
              " ('easily', 'RB'),\n",
              " ('outdistanced', 'NN'),\n",
              " ('the', 'DT'),\n",
              " ('4.1', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('return', 'NN'),\n",
              " ('from', 'IN'),\n",
              " ('junk', 'NN'),\n",
              " ('bonds', 'NNS'),\n",
              " (',', ','),\n",
              " (\"''\", \"''\"),\n",
              " ('wrote', 'VBD'),\n",
              " ('*T*-1', '-NONE-'),\n",
              " ('Moody', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('economist', 'NN'),\n",
              " ('John', 'NNP'),\n",
              " ('Lonski', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('yesterday', 'NN'),\n",
              " (\"'s\", 'POS'),\n",
              " ('market', 'NN'),\n",
              " ('report', 'NN'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('Little', 'NNP'),\n",
              " ('wonder', 'NN'),\n",
              " ('that', 'IN'),\n",
              " ('buyers', 'NNS'),\n",
              " ('for', 'IN'),\n",
              " ('junk', 'NN'),\n",
              " ('have', 'VBP'),\n",
              " ('been', 'VBN'),\n",
              " ('found', 'VBD'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('wanting', 'NN'),\n",
              " (',', ','),\n",
              " (\"''\", \"''\"),\n",
              " ('he', 'PRP'),\n",
              " ('said', 'VBD'),\n",
              " ('*T*-2', '-NONE-'),\n",
              " ('.', '.'),\n",
              " ('Moody', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('said', 'VBD'),\n",
              " ('0', '-NONE-'),\n",
              " ('the', 'DT'),\n",
              " ('average', 'JJ'),\n",
              " ('net', 'JJ'),\n",
              " ('asset', 'NN'),\n",
              " ('value', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('24', 'CD'),\n",
              " ('junk-bond', 'JJ'),\n",
              " ('mutual', 'JJ'),\n",
              " ('funds', 'NNS'),\n",
              " ('fell', 'VBD'),\n",
              " ('by', 'IN'),\n",
              " ('4.2', 'NN'),\n",
              " ('%', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('October', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Mortgage-Backed', 'NN'),\n",
              " ('Issues', 'NN'),\n",
              " ('Mortgage', 'NNP'),\n",
              " ('securities', 'NNS'),\n",
              " ('ended', 'VBD'),\n",
              " ('slightly', 'RB'),\n",
              " ('higher', 'JJR'),\n",
              " ('but', 'CC'),\n",
              " ('trailed', 'VBD'),\n",
              " ('gains', 'NNS'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('Treasury', 'NNP'),\n",
              " ('market', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Ginnie', 'NN'),\n",
              " ('Mae', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('9', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('issue', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('November', 'NNP'),\n",
              " ('delivery', 'NN'),\n",
              " ('finished', 'VBD'),\n",
              " ('at', 'IN'),\n",
              " ('98', 'CD'),\n",
              " ('5\\\\/8', 'CD'),\n",
              " (',', ','),\n",
              " ('up', 'RP'),\n",
              " ('2\\\\/32', 'NN'),\n",
              " (',', ','),\n",
              " ('and', 'CC'),\n",
              " ('its', 'PRP$'),\n",
              " ('9', 'CD'),\n",
              " ('1\\\\/2', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('issue', 'NN'),\n",
              " ('at', 'IN'),\n",
              " ('100', 'CD'),\n",
              " ('22\\\\/32', 'NN'),\n",
              " (',', ','),\n",
              " ('also', 'RB'),\n",
              " ('up', 'RP'),\n",
              " ('2\\\\/32', 'NN'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('Ginnie', 'NN'),\n",
              " ('Mae', 'NNP'),\n",
              " ('9', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('securities', 'NNS'),\n",
              " ('were', 'VBD'),\n",
              " ('yielding', 'VBG'),\n",
              " ('9.32', 'NN'),\n",
              " ('%', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('a', 'DT'),\n",
              " ('12-year', 'NN'),\n",
              " ('average', 'JJ'),\n",
              " ('life', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Activity', 'NN'),\n",
              " ('was', 'VBD'),\n",
              " ('light', 'JJ'),\n",
              " ('in', 'IN'),\n",
              " ('derivative', 'NN'),\n",
              " ('markets', 'NNS'),\n",
              " (',', ','),\n",
              " ('with', 'IN'),\n",
              " ('no', 'DT'),\n",
              " ('new', 'JJ'),\n",
              " ('issues', 'NNS'),\n",
              " ('priced', 'VBN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('.', '.'),\n",
              " ('Municipal', 'NNP'),\n",
              " ('Issues', 'NN'),\n",
              " ('Municipal', 'NNP'),\n",
              " ('bonds', 'NNS'),\n",
              " ('were', 'VBD'),\n",
              " ('mostly', 'RB'),\n",
              " ('unchanged', 'JJ'),\n",
              " ('to', 'TO'),\n",
              " ('up', 'RP'),\n",
              " ('1\\\\/8', 'CD'),\n",
              " ('point', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('light', 'JJ'),\n",
              " (',', ','),\n",
              " ('cautious', 'JJ'),\n",
              " ('trading', 'NN'),\n",
              " ('prior', 'RB'),\n",
              " ('to', 'TO'),\n",
              " ('tomorrow', 'NN'),\n",
              " (\"'s\", 'POS'),\n",
              " ('unemployment', 'NN'),\n",
              " ('report', 'NN'),\n",
              " ('.', '.'),\n",
              " ('A', 'DT'),\n",
              " ('$', '$'),\n",
              " ('114', 'NN'),\n",
              " ('million', 'CD'),\n",
              " ('*U*', '-NONE-'),\n",
              " ('issue', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('health', 'NN'),\n",
              " ('facility', 'NN'),\n",
              " ('revenue', 'NN'),\n",
              " ('bonds', 'NNS'),\n",
              " ('from', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('California', 'NNP'),\n",
              " ('Health', 'NNP'),\n",
              " ('Facilities', 'NN'),\n",
              " ('Financing', 'NN'),\n",
              " ('Authority', 'NN'),\n",
              " ('was', 'VBD'),\n",
              " ('temporarily', 'RB'),\n",
              " ('withdrawn', 'VBN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('after', 'IN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('being', 'VBG'),\n",
              " ('tentatively', 'RB'),\n",
              " ('priced', 'VBN'),\n",
              " ('*-2', '-NONE-'),\n",
              " ('by', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('First', 'NNP'),\n",
              " ('Boston', 'NNP'),\n",
              " ('Corp.', 'NNP'),\n",
              " ('group', 'NN'),\n",
              " ('.', '.'),\n",
              " ('An', 'DT'),\n",
              " ('official', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('lead', 'VB'),\n",
              " ('underwriter', 'NN'),\n",
              " ('declined', 'VBD'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('comment', 'NN'),\n",
              " ('on', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('reason', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('delay', 'VBP'),\n",
              " (',', ','),\n",
              " ('but', 'CC'),\n",
              " ('market', 'NN'),\n",
              " ('participants', 'NNS'),\n",
              " ('speculated', 'VBD'),\n",
              " ('that', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('number', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('factors', 'NNS'),\n",
              " (',', ','),\n",
              " ('including', 'VBG'),\n",
              " ('a', 'DT'),\n",
              " ('lack', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('investor', 'NN'),\n",
              " ('interest', 'NN'),\n",
              " (',', ','),\n",
              " ('were', 'VBD'),\n",
              " ('responsible', 'JJ'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('issue', 'NN'),\n",
              " ('could', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('relaunched', 'NN'),\n",
              " ('*-1', '-NONE-'),\n",
              " (',', ','),\n",
              " ('possibly', 'RB'),\n",
              " ('in', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('restructured', 'VBD'),\n",
              " ('form', 'NN'),\n",
              " (',', ','),\n",
              " ('as', 'IN'),\n",
              " ('early', 'JJ'),\n",
              " ('as', 'IN'),\n",
              " ('next', 'JJ'),\n",
              " ('week', 'NN'),\n",
              " (',', ','),\n",
              " ('according', 'VBG'),\n",
              " ('to', 'TO'),\n",
              " ('the', 'DT'),\n",
              " ('lead', 'VB'),\n",
              " ('underwriter', 'NN'),\n",
              " ('.', '.'),\n",
              " ('A', 'DT'),\n",
              " ('$', '$'),\n",
              " ('107.03', 'NN'),\n",
              " ('million', 'CD'),\n",
              " ('*U*', '-NONE-'),\n",
              " ('offering', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('Santa', 'NNP'),\n",
              " ('Ana', 'NNP'),\n",
              " ('Community', 'NNP'),\n",
              " ('Redevelopment', 'NNP'),\n",
              " ('Agency', 'NNP'),\n",
              " (',', ','),\n",
              " ('Calif.', 'NNP'),\n",
              " (',', ','),\n",
              " ('tax', 'NN'),\n",
              " ('allocation', 'NN'),\n",
              " ('bonds', 'NNS'),\n",
              " ('got', 'VBD'),\n",
              " ('off', 'RP'),\n",
              " ('to', 'TO'),\n",
              " ('a', 'DT'),\n",
              " ('slow', 'JJ'),\n",
              " ('start', 'VB'),\n",
              " ('and', 'CC'),\n",
              " ('may', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('repriced', 'NN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('at', 'IN'),\n",
              " ('lower', 'JJR'),\n",
              " ('levels', 'NNS'),\n",
              " ('today', 'NN'),\n",
              " (',', ','),\n",
              " ('according', 'VBG'),\n",
              " ('to', 'TO'),\n",
              " ('an', 'DT'),\n",
              " ('official', 'NN'),\n",
              " ('with', 'IN'),\n",
              " ('lead', 'VB'),\n",
              " ('underwriter', 'NN'),\n",
              " ('Donaldson', 'NNP'),\n",
              " ('Lufkin', 'NNP'),\n",
              " ('&', 'CC'),\n",
              " ('Jenrette', 'NNP'),\n",
              " ('Securities', 'NNPS'),\n",
              " ('Corp', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('Santa', 'NNP'),\n",
              " ('Ana', 'NNP'),\n",
              " ('bonds', 'NNS'),\n",
              " ('were', 'VBD'),\n",
              " ('tentatively', 'RB'),\n",
              " ('priced', 'VBN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('*-2', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('yield', 'NN'),\n",
              " ('from', 'IN'),\n",
              " ('6.40', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('1991', 'CD'),\n",
              " ('to', 'TO'),\n",
              " ('7.458', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('Bucking', 'NN'),\n",
              " ('the', 'DT'),\n",
              " ('market', 'NN'),\n",
              " ('trend', 'NN'),\n",
              " (',', ','),\n",
              " ('an', 'DT'),\n",
              " ('issue', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('$', '$'),\n",
              " ('130', 'CD'),\n",
              " ('million', 'CD'),\n",
              " ('*U*', '-NONE-'),\n",
              " ('general', 'JJ'),\n",
              " ('obligation', 'NN'),\n",
              " ('distributable', 'JJ'),\n",
              " ('state', 'NN'),\n",
              " ('aid', 'NN'),\n",
              " ('bonds', 'NNS'),\n",
              " ('from', 'IN'),\n",
              " ('Detroit', 'NNP'),\n",
              " (',', ','),\n",
              " ('Mich.', 'NNP'),\n",
              " (',', ','),\n",
              " ('apparently', 'RB'),\n",
              " ('drew', 'NN'),\n",
              " ('solid', 'JJ'),\n",
              " ('investor', 'NN'),\n",
              " ('interest', 'NN'),\n",
              " ('.', '.'),\n",
              " ('They', 'PRP'),\n",
              " ('were', 'VBD'),\n",
              " ('tentatively', 'RB'),\n",
              " ('priced', 'VBN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('*-2', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('yield', 'NN'),\n",
              " ('from', 'IN'),\n",
              " ('6.20', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('1991', 'CD'),\n",
              " ('to', 'TO'),\n",
              " ('7.272', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('Foreign', 'NNP'),\n",
              " ('Bond', 'NN'),\n",
              " ('West', 'NNP'),\n",
              " ('German', 'JJ'),\n",
              " ('dealers', 'NNS'),\n",
              " ('said', 'VBD'),\n",
              " ('0', '-NONE-'),\n",
              " ('there', 'EX'),\n",
              " ('was', 'VBD'),\n",
              " ('little', 'JJ'),\n",
              " ('interest', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('Treasury', 'NNP'),\n",
              " ('bonds', 'NNS'),\n",
              " ('ahead', 'RB'),\n",
              " ('of', 'IN'),\n",
              " ('Thursday', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('new', 'JJ'),\n",
              " ('government', 'NN'),\n",
              " ('bond', 'NN'),\n",
              " ('issue', 'NN'),\n",
              " ('.', '.'),\n",
              " ('So', 'RB'),\n",
              " ('far', 'RB'),\n",
              " (',', ','),\n",
              " ('they', 'PRP'),\n",
              " ('said', 'VBD'),\n",
              " ('0', '-NONE-'),\n",
              " ('*T*-2', '-NONE-'),\n",
              " (',', ','),\n",
              " ('investors', 'NNS'),\n",
              " ('appear', 'VBP'),\n",
              " ('unenthusiastic', 'NN'),\n",
              " ('about', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('new', 'JJ'),\n",
              " ('issue', 'NN'),\n",
              " ('which', 'WDT'),\n",
              " ('*T*-1', '-NONE-'),\n",
              " ('might', 'MD'),\n",
              " ('force', 'NN'),\n",
              " ('the', 'DT'),\n",
              " ('government', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('raise', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('coupon', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('more', 'JJR'),\n",
              " ('than', 'IN'),\n",
              " ('7', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('.', '.'),\n",
              " ('It', 'PRP'),\n",
              " ('is', 'VBZ'),\n",
              " ('generally', 'RB'),\n",
              " ('expected', 'VBN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('be', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('usual', 'JJ'),\n",
              " ('10-year', 'JJ'),\n",
              " (',', ','),\n",
              " ('four', 'CD'),\n",
              " ('billion', 'CD'),\n",
              " ('mark', 'NN'),\n",
              " ('issue', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Rumors', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('the', 'DT'),\n",
              " ('contrary', 'JJ'),\n",
              " ('have', 'VBP'),\n",
              " ('been', 'VBN'),\n",
              " ('that', 'IN'),\n",
              " ('it', 'PRP'),\n",
              " ('would', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('a', 'DT'),\n",
              " ('six', 'CD'),\n",
              " ('billion', 'CD'),\n",
              " ('mark', 'NN'),\n",
              " ('issue', 'NN'),\n",
              " (',', ','),\n",
              " ('or', 'CC'),\n",
              " ('that', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('last', 'JJ'),\n",
              " ('Bund', 'NN'),\n",
              " (',', ','),\n",
              " ('a', 'DT'),\n",
              " ('7', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('issue', 'NN'),\n",
              " ('due', 'JJ'),\n",
              " ('October', 'NNP'),\n",
              " ('1999', 'CD'),\n",
              " (',', ','),\n",
              " ('would', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('increased', 'VBN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('by', 'IN'),\n",
              " ('two', 'CD'),\n",
              " ('billion', 'CD'),\n",
              " ('marks', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('Elsewhere', 'RB'),\n",
              " (':', ':'),\n",
              " ('--', ':'),\n",
              " ('In', 'IN'),\n",
              " ('Japan', 'NNP'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " ('benchmark', 'NN'),\n",
              " ('No.', 'NN'),\n",
              " ('111', 'NN'),\n",
              " ('4.6', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('issue', 'NN'),\n",
              " ('due', 'JJ'),\n",
              " ('1998', 'NN'),\n",
              " ('ended', 'VBD'),\n",
              " ('on', 'IN'),\n",
              " ('brokers', 'NNS'),\n",
              " ('screens', 'NNS'),\n",
              " ('unchanged', 'JJ'),\n",
              " ('at', 'IN'),\n",
              " ('95.09', 'NN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('yield', 'NN'),\n",
              " ('5.435', 'NN'),\n",
              " ('%', 'NN'),\n",
              " ('.', '.'),\n",
              " ('--', ':'),\n",
              " ('In', 'IN'),\n",
              " ('Britain', 'NNP'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " ('benchmark', 'NN'),\n",
              " ('11', 'CD'),\n",
              " ('3\\\\/4', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('bond', 'NN'),\n",
              " ('due', 'JJ'),\n",
              " ('2003\\\\/2007', 'NN'),\n",
              " ('fell', 'VBD'),\n",
              " ('14\\\\/32', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('111', 'NN'),\n",
              " ('2\\\\/32', 'NN'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('yield', 'NN'),\n",
              " ('10.19', 'NN'),\n",
              " ('%', 'NN'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('12', 'CD'),\n",
              " ('%', 'NN'),\n",
              " ('notes', 'NNS'),\n",
              " ('due', 'JJ'),\n",
              " ('1995', 'NN'),\n",
              " ('fell', 'VBD'),\n",
              " ('9\\\\/32', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('103', 'NN'),\n",
              " ('3\\\\/8', 'CD'),\n",
              " ('*-1', '-NONE-'),\n",
              " ('to', 'TO'),\n",
              " ('yield', 'NN'),\n",
              " ('11.10', 'NN'),\n",
              " ('%', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Standard', 'NNP'),\n",
              " ('&', 'CC'),\n",
              " ('Poor', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('Corp.', 'NNP'),\n",
              " ('lowered', 'VBN'),\n",
              " ('to', 'TO'),\n",
              " ('double-C', 'NN'),\n",
              " ('from', 'IN'),\n",
              " ('triple-C', 'NN'),\n",
              " ('the', 'DT'),\n",
              " ('rating', 'NN'),\n",
              " ('on', 'IN'),\n",
              " ('about', 'IN'),\n",
              " ('$', '$'),\n",
              " ('130', 'CD'),\n",
              " ('million', 'CD'),\n",
              " ('*U*', '-NONE-'),\n",
              " ('of', 'IN'),\n",
              " ('debt', 'NN'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('rating', 'NN'),\n",
              " ('concern', 'NN'),\n",
              " ('said', 'VBD'),\n",
              " ('0', '-NONE-'),\n",
              " ('the', 'DT'),\n",
              " ('textile', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('clothing', 'NN'),\n",
              " ('company', 'NN'),\n",
              " (\"'s\", 'POS'),\n",
              " ('interest', 'NN'),\n",
              " ('expense', 'NN'),\n",
              " ('exceeds', 'NN'),\n",
              " ('operating', 'NN'),\n",
              " ('profit', 'NN'),\n",
              " ('``', '``'),\n",
              " ('by', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('wide', 'JJ'),\n",
              " ('margin', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " ('and', 'CC'),\n",
              " ('it', 'PRP'),\n",
              " ('noted', 'VBD'),\n",
              " ('United', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('estimated', 'VBN'),\n",
              " ('after-tax', 'JJ'),\n",
              " ('loss', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('$', '$'),\n",
              " ('24', 'CD'),\n",
              " ('million', 'CD'),\n",
              " ('*U*', '-NONE-'),\n",
              " ('for', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('year', 'NN'),\n",
              " ('ended', 'VBD'),\n",
              " ('June', 'NNP'),\n",
              " ('30', 'CD'),\n",
              " ('.', '.'),\n",
              " ('Travelers', 'NNPS'),\n",
              " ('Corp.', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('third-quarter', 'JJ'),\n",
              " ('net', 'JJ'),\n",
              " ('income', 'NN'),\n",
              " ('rose', 'VBD'),\n",
              " ('11', 'CD'),\n",
              " ('%', 'NN'),\n",
              " (',', ','),\n",
              " ('even', 'RB'),\n",
              " ('though', 'IN'),\n",
              " ('claims', 'VBZ'),\n",
              " ('stemming', 'VBG'),\n",
              " ('from', 'IN'),\n",
              " ('Hurricane', 'NN'),\n",
              " ('Hugo', 'NN'),\n",
              " ('reduced', 'VBN'),\n",
              " ('results', 'NNS'),\n",
              " ('$', '$'),\n",
              " ('40', 'CD'),\n",
              " ('million', 'CD'),\n",
              " ('*U*', '-NONE-'),\n",
              " ('.', '.'),\n",
              " ('Net', 'JJ'),\n",
              " ('advanced', 'VBD'),\n",
              " ('to', 'TO'),\n",
              " ('$', '$'),\n",
              " ('94.2', 'NN'),\n",
              " ('million', 'CD'),\n",
              " ('*U*', '-NONE-'),\n",
              " (',', ','),\n",
              " ('or', 'CC'),\n",
              " ('89', 'CD'),\n",
              " ('cents', 'NNS'),\n",
              " ('a', 'DT'),\n",
              " ('share', 'NN'),\n",
              " (',', ','),\n",
              " ('from', 'IN'),\n",
              " ('$', '$'),\n",
              " ('85', 'CD'),\n",
              " ('million', 'CD'),\n",
              " ('*U*', '-NONE-'),\n",
              " (',', ','),\n",
              " ('or', 'CC'),\n",
              " ('83', 'NN'),\n",
              " ('cents', 'NNS'),\n",
              " ('a', 'DT'),\n",
              " ('share', 'NN'),\n",
              " (',', ','),\n",
              " ('including', 'VBG'),\n",
              " ('net', 'JJ'),\n",
              " ('realized', 'VBD'),\n",
              " ('investment', 'NN'),\n",
              " ('gains', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('$', '$'),\n",
              " ('31', 'CD'),\n",
              " ('million', 'CD'),\n",
              " ('*U*', '-NONE-'),\n",
              " (',', ','),\n",
              " ('up', 'RP'),\n",
              " ('from', 'IN'),\n",
              " ('$', '$'),\n",
              " ('10', 'CD'),\n",
              " ('million', 'CD'),\n",
              " ('*U*', '-NONE-'),\n",
              " ('a', 'DT'),\n",
              " ('year', 'NN'),\n",
              " ('ago', 'RB'),\n",
              " ('.', '.'),\n",
              " ('But', 'CC'),\n",
              " ('revenue', 'NN'),\n",
              " ('declined', 'VBD'),\n",
              " ('to', 'TO'),\n",
              " ('$', '$'),\n",
              " ('3', 'CD'),\n",
              " ('billion', 'CD'),\n",
              " ('*U*', '-NONE-'),\n",
              " ('from', 'IN'),\n",
              " ...]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_toks,test_tags=zip(*test)\n",
        "uni_pos_tag(test_toks,unigram_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jTQsUrlFvwe"
      },
      "source": [
        "### Exercise 3.3\n",
        "Write a function `evaluate_uni_pos_tag` which will calculate the accuracy of the `uni_pos_tag` function. This should have as arguments:\n",
        "* the unigram_model\n",
        "* the gold standard sequence of (token,tag) pairs for comparison\n",
        "\n",
        "You should find that it is 96% accurate on the training data.  How accurate is it on the test data? \n",
        "\n",
        "As an extension, you could implement a uni_pos_tagger class, which combines the all of the functionality above, and then provide an `evaluate` function which evaluates a tagger. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFmQ_ZgjFvwf"
      },
      "outputs": [],
      "source": [
        "def evaluate_uni_pos_tag(unigram_model,goldstandard):\n",
        "    goldtoks,goldtags=zip(*goldstandard)\n",
        "    pretoks,pretags=zip(*uni_pos_tag(goldtoks,unigram_model))\n",
        "    print(goldtags[:10])\n",
        "    print(pretags[:10])\n",
        "    n=len(pretags)\n",
        "    correct=0\n",
        "    for (pre,gold) in zip(pretags,goldtags):\n",
        "        if pre==gold:\n",
        "            correct+=1\n",
        "    return correct/n\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnAThHYEFvwh",
        "outputId": "6ba93339-2487-4561-e77c-a22ec569ab6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT')\n",
            "('NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.959709461137323"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_uni_pos_tag(unigram_model,train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olWTComLFvwk",
        "outputId": "68d61bf3-5bb2-4629-dc00-1c541ae267a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('DT', 'NNP', 'VBD', '-NONE-', 'DT', 'NN', 'VBZ', 'NN', 'IN', 'JJ')\n",
            "('DT', 'NNP', 'VBD', '-NONE-', 'DT', 'NN', 'VBZ', 'NN', 'IN', 'JJ')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8783770361541517"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_uni_pos_tag(unigram_model,test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85cP6GboFvwm"
      },
      "source": [
        "## Beyond Unigram Tagging\n",
        "State-of-the-art POS-taggers use information about likely sequences of tags to get higher performance.\n",
        "\n",
        "In the lectures, we discussed the theory of Hidden Markov Model (HMM) tagging.  Here we are going to experiment with the HMM tagger available in NLTK.  First, however, we need to segment our sequence of (token,tag) pairs into a collection of shorter sequences (which roughly correspond with sentences).   This is because the Viterbi algorithm will try to find the best sequence of tags by considering the whole sequence.  Therefore, we want to reduce the maximum length of sequences for both efficiency and accuracy reasons  We are just going to split the sequence on every token which is tagged as a full stop. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vszxRY-vU1kV"
      },
      "outputs": [],
      "source": [
        "def sentence_split(labelledsequence):\n",
        "    #this is going to do a very rough job - just splitting on '.'\n",
        "    #due to the tags, we can't rejoin, use the sentence splitter and then re-tokenise\n",
        "    #we could do a better job than this, but don't really need to\n",
        "    #we just want to split the input up so that the HMM tagger doesn't view it as one long sequence which it needs to run Viterbi over\n",
        "    \n",
        "    sentences=[]\n",
        "    \n",
        "    sentence=[]\n",
        "    for token,tag in labelledsequence:\n",
        "        sentence.append((token,tag))\n",
        "        if tag=='.':\n",
        "            sentences.append(sentence)\n",
        "            sentence=[]\n",
        "    return sentences\n",
        "\n",
        "train_sentences=sentence_split(train)\n",
        "test_sentences=sentence_split(test)\n",
        "print(\"Number of training sentences: {}\".format(len(train_sentences)))\n",
        "print(\"Number of testing sentences: {}\".format(len(test_sentences)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLSx5Zv4U1kV"
      },
      "source": [
        "We can now import the `nltk.tag.hmm` library.  To create a HiddenMarkovModelTagger, we first need a HiddenMarkovModelTrainer.  The train_supervised() method of this class will take the training sentences, estimate the emission and transition probabilities and return a HiddenMarkovModelTagger with these parameters.\n",
        "\n",
        "We can then run this HiddenMarkovModelTagger on unlabelled sequences using its `.tag()` method or test it on labelled sequences using its `.test()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrvL-ilPU1kV"
      },
      "outputs": [],
      "source": [
        "from nltk.tag import hmm\n",
        "hmmTrainer = hmm.HiddenMarkovModelTrainer([],[])\n",
        "hmmTagger =hmmTrainer.train_supervised(train_sentences)\n",
        "hmmTagger.test(train_sentences)\n",
        "hmmTagger.test(test_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAbGZx3vU1kV"
      },
      "source": [
        "Note that the trained hmmTagger does really well at predicting the tags in the training sample but really badly at predicting the tags in the testing sample.  This is partly due to the small size of the training sample.  There are lots of tokens and tag transitions in the testing sample which haven't been seen before in the training sample.  We can improve this by smoothing the probability estimates.  By default, the `train_supervised` method uses a plain Maximum Likelihood Estimator to convert the observed frequency distributions into probability distributions.  However, we can pass it a different estimator which will carry out smoothing on the distributions.  Here we are going to use the LidstoneProbDist which will \"add-gamma\" to all of the counts (where gamma is a small number). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSFKynW6U1kV"
      },
      "outputs": [],
      "source": [
        "from nltk.probability import MLEProbDist,LidstoneProbDist\n",
        "\n",
        "#this is the default estimator used by HiddenMarkovModelTrainer.trained_supervised\n",
        "default_estimator = lambda fdist, bins: MLEProbDist(fdist,bins)\n",
        "\n",
        "#we are going to replace it with this\n",
        "gamma=1\n",
        "smoothed_estimator = lambda fdist, bins: LidstoneProbDist(fdist,gamma,bins)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTTI5p8zU1kV"
      },
      "outputs": [],
      "source": [
        "hmmTagger_smooth =hmmTrainer.train_supervised(train_sentences,estimator=smoothed_estimator)\n",
        "hmmTagger_smooth.test(train_sentences)\n",
        "hmmTagger_smooth.test(test_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb1qee0LU1kV"
      },
      "source": [
        "We can see that the accuracy on the training data has gone down but the accuracy on the testing data has improved a lot.  Smoothing appears to be helping, but maybe we can do better with a different value of gamma?\n",
        "\n",
        "First, we will need our own test function as unfortunately, hmmTagger.test() only prints the accuracy and does not return it for future use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_saYQOnU1kW"
      },
      "outputs": [],
      "source": [
        "def evaluate(labelledsequences,tagger=hmmTagger):\n",
        "    count=0\n",
        "    correct=0\n",
        "    for sequence in labelledsequences:\n",
        "        goldtoks,goldtags=zip(*sequence)\n",
        "        goldtoks=list(goldtoks)\n",
        "        #print(goldtoks)\n",
        "        predictions=tagger.tag(goldtoks)\n",
        "        predtoks,predtags=zip(*predictions)\n",
        "        for g,p in zip(goldtags,predtags):\n",
        "            if g==p:\n",
        "                correct+=1\n",
        "            count+=1\n",
        "    return correct/count\n",
        "evaluate(test_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY5kJI0BU1kW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLmDPbIbU1kW"
      },
      "source": [
        "### Exercise 4\n",
        "\n",
        "Carry out an experiment to find the optimal value of gamma.  You should:\n",
        "    * experiment with different values of gamma using a training and validation set (created from the training set above)\n",
        "    * ideally average over a number of runs with different training, validation splits\n",
        "    * plot a graph of accuracy against gamma on both training and validation\n",
        "    * finally train a HmmTagger on all of the training data using the optimal value of gamma and evaluate its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XP8JX5gPU1kW"
      },
      "outputs": [],
      "source": [
        "def random_split(labelledsequences,ratio=0.8):\n",
        "    n=len(labelledsequences)\n",
        "    tr_indices=set(random.sample(range(n),int(n*ratio)))\n",
        "    test_indices=set(range(n))-tr_indices\n",
        "    train=[labelledsequences[i] for i in tr_indices]\n",
        "    dev=[labelledsequences[i] for i in test_indices]\n",
        "    return train,dev\n",
        "    \n",
        "train,dev=random_split(train_sentences)\n",
        "print(dev[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ru_0ydE2U1kW"
      },
      "outputs": [],
      "source": [
        "#this will take some time to run\n",
        "\n",
        "gamma_values=[0,0.001,0.01,0.05,0.1,0.2,0.4,0.5,0.75,1,2]\n",
        "#gamma_values=[0,1]\n",
        "number_of_runs=3\n",
        "\n",
        "train_accs={}\n",
        "dev_accs={}\n",
        "\n",
        "for run in range(number_of_runs):\n",
        "    train,dev=random_split(train_sentences)\n",
        "    \n",
        "    for gamma in gamma_values:\n",
        "        smoothed_estimator = lambda fdist, bins: LidstoneProbDist(fdist,gamma,bins)\n",
        "        hmmTagger_smooth =hmmTrainer.train_supervised(train,estimator=smoothed_estimator)\n",
        "        train_acc=evaluate(train,hmmTagger_smooth)\n",
        "        dev_acc=evaluate(dev,hmmTagger_smooth)\n",
        "        print(\"{}: {}: {}\".format(gamma,train_acc,dev_acc))\n",
        "        train_accs[gamma]=train_accs.get(gamma,0)+train_acc/number_of_runs\n",
        "        dev_accs[gamma]=dev_accs.get(gamma,0)+dev_acc/number_of_runs\n",
        "        \n",
        "print(train_accs)\n",
        "print(dev_accs)\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLMlk58NU1kW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u6ZItM3U1kW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "results=[]\n",
        "for key,value in train_accs.items():\n",
        "    results.append((key,value,dev_accs.get(key,0)))\n",
        "accuracy_df=pd.DataFrame(results,columns=['gamma','training_acc','dev_acc'])\n",
        "accuracy_df.plot(x='gamma')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXC0c6xwU1kW"
      },
      "source": [
        "Choose best gamma and then retrain on whole training set.  What is performance on test set?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mimo9-VrU1kW"
      },
      "outputs": [],
      "source": [
        "gamma=0.01\n",
        "smoothed_estimator = lambda fdist, bins: LidstoneProbDist(fdist,gamma,bins)\n",
        "hmmTagger_smooth =hmmTrainer.train_supervised(train_sentences,estimator=smoothed_estimator)\n",
        "hmmTagger_smooth.test(train_sentences)\n",
        "hmmTagger_smooth.test(test_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcT-LhWKFvwx"
      },
      "source": [
        "\n",
        "\n",
        "### Extension\n",
        "Find examples where the unigram tagger makes mistakes but the nltk hmm tagger is correct.  What different types of errors are being made?  Can you explain intuitively why the correct sequence predicted by the nltk hmm tagger is more likely than the one predicted by the unigram tagger?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIC5sMwjFvwy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "def compare_pos_taggers(goldstandard,unigram_model):\n",
        "    #this assumes flattened list so needs updating\n",
        "    goldtoks,goldtags=zip(*goldstandard)\n",
        "    pretoks,pretags=zip(*hmmTagger_smooth.tag(goldtoks))\n",
        "    unitoks,unitags=zip(*uni_pos_tag(goldtoks,unigram_model))\n",
        "    \n",
        "    #find\n",
        "    examples=[]\n",
        "    for i,(gold,pre,uni) in enumerate(zip(goldtags,pretags,unitags)):\n",
        "        if gold==pre and gold!=uni:\n",
        "            examples.append(i)\n",
        "        \n",
        "    #display\n",
        "    headers=['correct/pre','unigram','before','after']\n",
        "    rows=[]\n",
        "    for e in examples:\n",
        "        rows.append([goldstandard[e],unitags[e],goldstandard[e-3:e],goldstandard[e+1:e+3]])\n",
        "        \n",
        "    df=pd.DataFrame(rows,columns=headers)\n",
        "    return df\n",
        "\n",
        "compare_pos_taggers(test,unigram_model)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kE63lP_Fvw0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVJV7Jk_Fvw4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBKDRkelc8_V"
      },
      "source": [
        "# Lecture Code for HMM Emission and Transition Probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qB3LMR1GFvw6"
      },
      "outputs": [],
      "source": [
        "def calculate_emissions(trainlist):\n",
        "    #trainlist is a list of (word,tag) pairs\n",
        "    emissions={}\n",
        "    for word,tag in trainlist:\n",
        "        current=emissions.get(tag,{})\n",
        "        current[word]=current.get(word,0)+1\n",
        "        emissions[tag]=current\n",
        "    return {tag:{word:value/sum(worddist.values()) for word,value in worddist.items()} \n",
        "            for tag,worddist in emissions.items()}\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_CK3JyKFvw8"
      },
      "outputs": [],
      "source": [
        "calculate_emissions(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KabkWZMyFvw_"
      },
      "outputs": [],
      "source": [
        "def calculate_transitions(trainlist):\n",
        "    transitions={}\n",
        "    previous=\"start\"\n",
        "    for _, tag in trainlist:\n",
        "        current=transitions.get(previous,{})\n",
        "        current[tag]=current.get(tag,0)+1\n",
        "        transitions[tag]=current\n",
        "        previous =tag\n",
        "    return {previous:{tag:value/sum(tagdist.values()) for tag,value in tagdist.items()} \n",
        "            for previous,tagdist in transitions.items()}\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4gMbmElFvxG"
      },
      "outputs": [],
      "source": [
        "calculate_transitions(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhUtBDXRFvxI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}